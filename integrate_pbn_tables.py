#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PBN í…Œì´ë¸” í†µí•© ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ controlDB.dbì— pbn_posts í…Œì´ë¸”ì„ ì¶”ê°€í•˜ì—¬ í•˜ë‚˜ì˜ DBë¡œ í†µí•©
"""

import sqlite3
import os
from pathlib import Path


def integrate_pbn_tables():
    """ê¸°ì¡´ controlDB.dbì— PBN í¬ìŠ¤íŠ¸ í…Œì´ë¸” ì¶”ê°€"""

    print("ğŸ”§ PBN í…Œì´ë¸” í†µí•© ì‹œì‘...")

    # ê¸°ì¡´ controlDB.dbì— ì—°ê²°
    control_db_path = "controlDB.db"

    if not os.path.exists(control_db_path):
        print("âŒ controlDB.db íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        with sqlite3.connect(control_db_path) as conn:
            cursor = conn.cursor()

            print("ğŸ“‹ ê¸°ì¡´ í…Œì´ë¸” í™•ì¸ ì¤‘...")
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            existing_tables = [row[0] for row in cursor.fetchall()]
            print(f"   ê¸°ì¡´ í…Œì´ë¸”: {existing_tables}")

            # PBN í¬ìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)
            print("ğŸ†• pbn_posts í…Œì´ë¸” ìƒì„± ì¤‘...")
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS pbn_posts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL,
                    site_url TEXT NOT NULL,
                    post_id INTEGER NOT NULL,
                    title TEXT NOT NULL,
                    url TEXT NOT NULL UNIQUE,
                    excerpt TEXT,
                    date_published TEXT,
                    word_count INTEGER DEFAULT 0,
                    categories TEXT,  -- JSON í˜•íƒœë¡œ ì €ì¥
                    tags TEXT,        -- JSON í˜•íƒœë¡œ ì €ì¥
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (site_id) REFERENCES pbn_sites (site_id)
                )
            """
            )

            # í¬ë¡¤ë§ ë¡œê·¸ í…Œì´ë¸” ìƒì„±
            print("ğŸ“Š crawl_logs í…Œì´ë¸” ìƒì„± ì¤‘...")
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS crawl_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL,
                    site_url TEXT NOT NULL,
                    total_posts INTEGER DEFAULT 0,
                    successful_posts INTEGER DEFAULT 0,
                    failed_posts INTEGER DEFAULT 0,
                    crawl_duration REAL DEFAULT 0,
                    status TEXT DEFAULT 'pending',
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (site_id) REFERENCES pbn_sites (site_id)
                )
            """
            )

            # ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
            print("ğŸ” ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_pbn_posts_site_id ON pbn_posts(site_id)",
                "CREATE INDEX IF NOT EXISTS idx_pbn_posts_title ON pbn_posts(title)",
                "CREATE INDEX IF NOT EXISTS idx_pbn_posts_url ON pbn_posts(url)",
                "CREATE INDEX IF NOT EXISTS idx_pbn_posts_date ON pbn_posts(date_published)",
                "CREATE INDEX IF NOT EXISTS idx_crawl_logs_site_id ON crawl_logs(site_id)",
                "CREATE INDEX IF NOT EXISTS idx_crawl_logs_status ON crawl_logs(status)",
            ]

            for index_sql in indexes:
                cursor.execute(index_sql)

            conn.commit()

            # í…Œì´ë¸” í™•ì¸
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            updated_tables = [row[0] for row in cursor.fetchall()]

            print("âœ… í…Œì´ë¸” í†µí•© ì™„ë£Œ!")
            print(f"ğŸ“‹ í˜„ì¬ í…Œì´ë¸”: {updated_tables}")

            # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
            print("\nğŸ“Š í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜:")
            for table in ["pbn_sites", "clients", "pbn_posts", "crawl_logs"]:
                if table in updated_tables:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    print(f"   {table}: {count:,}ê°œ")

            return True

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” í†µí•© ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def migrate_existing_data():
    """ê¸°ì¡´ pbn_content_database.db ë°ì´í„°ë¥¼ controlDB.dbë¡œ ì´ì „"""

    old_db_path = "pbn_content_database.db"
    control_db_path = "controlDB.db"

    if not os.path.exists(old_db_path):
        print("â„¹ï¸ ê¸°ì¡´ pbn_content_database.dbê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return True

    print("ğŸ”„ ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")

    try:
        # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
        with sqlite3.connect(old_db_path) as old_conn:
            old_cursor = old_conn.cursor()

            # pbn_posts ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            old_cursor.execute(
                """
                SELECT site_id, site_url, post_id, title, url, excerpt, 
                       date_published, word_count, categories, tags
                FROM pbn_posts
            """
            )
            posts_data = old_cursor.fetchall()

            # crawl_logs ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            old_cursor.execute(
                """
                SELECT site_id, site_url, total_posts, successful_posts, 
                       failed_posts, crawl_duration, status, error_message
                FROM crawl_logs
            """
            )
            logs_data = old_cursor.fetchall()

        # ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
        with sqlite3.connect(control_db_path) as new_conn:
            new_cursor = new_conn.cursor()

            # í¬ìŠ¤íŠ¸ ë°ì´í„° ì‚½ì…
            if posts_data:
                print(f"ğŸ“„ {len(posts_data)}ê°œ í¬ìŠ¤íŠ¸ ë°ì´í„° ì´ì „ ì¤‘...")
                new_cursor.executemany(
                    """
                    INSERT OR IGNORE INTO pbn_posts 
                    (site_id, site_url, post_id, title, url, excerpt, 
                     date_published, word_count, categories, tags)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    posts_data,
                )

            # ë¡œê·¸ ë°ì´í„° ì‚½ì…
            if logs_data:
                print(f"ğŸ“Š {len(logs_data)}ê°œ ë¡œê·¸ ë°ì´í„° ì´ì „ ì¤‘...")
                new_cursor.executemany(
                    """
                    INSERT OR IGNORE INTO crawl_logs 
                    (site_id, site_url, total_posts, successful_posts, 
                     failed_posts, crawl_duration, status, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    logs_data,
                )

            new_conn.commit()

        print("âœ… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")

        # ê¸°ì¡´ íŒŒì¼ ë°±ì—… í›„ ì‚­ì œ ì—¬ë¶€ í™•ì¸
        backup_path = f"{old_db_path}.backup"
        os.rename(old_db_path, backup_path)
        print(f"ğŸ“¦ ê¸°ì¡´ DBë¥¼ {backup_path}ë¡œ ë°±ì—…í–ˆìŠµë‹ˆë‹¤.")

        return True

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def update_crawler_to_use_control_db():
    """í¬ë¡¤ëŸ¬ê°€ controlDB.dbë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •"""

    print("ğŸ”§ í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘...")

    # pbn_content_crawler.py íŒŒì¼ ìˆ˜ì •
    crawler_file = "pbn_content_crawler.py"

    if not os.path.exists(crawler_file):
        print("âŒ pbn_content_crawler.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        # íŒŒì¼ ì½ê¸°
        with open(crawler_file, "r", encoding="utf-8") as f:
            content = f.read()

        # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ë³€ê²½
        updated_content = content.replace(
            'db_path: str = "pbn_content_database.db"', 'db_path: str = "controlDB.db"'
        )

        # íŒŒì¼ ì“°ê¸°
        with open(crawler_file, "w", encoding="utf-8") as f:
            f.write(updated_content)

        print("âœ… í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        return True

    except Exception as e:
        print(f"âŒ í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def main():
    """ë©”ì¸ í†µí•© í”„ë¡œì„¸ìŠ¤"""

    print("ğŸš€ PBN ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹œì‘")
    print("=" * 50)

    steps = [
        ("í…Œì´ë¸” êµ¬ì¡° í†µí•©", integrate_pbn_tables),
        ("ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜", migrate_existing_data),
        ("í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸", update_crawler_to_use_control_db),
    ]

    success_count = 0

    for step_name, step_func in steps:
        print(f"\nğŸ”„ {step_name} ì‹¤í–‰ ì¤‘...")

        if step_func():
            print(f"âœ… {step_name} ì™„ë£Œ")
            success_count += 1
        else:
            print(f"âŒ {step_name} ì‹¤íŒ¨")
            break

    print("\n" + "=" * 50)
    if success_count == len(steps):
        print("ğŸ‰ ëª¨ë“  í†µí•© ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. python enhanced_main_v2.py ì‹¤í–‰")
        print("2. ë©”ë‰´ì—ì„œ '21. PBN ì½˜í…ì¸  í¬ë¡¤ë§' ì„ íƒ")
        print("3. í¬ë¡¤ë§ ì™„ë£Œ í›„ ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ ì‚¬ìš©")
    else:
        print(f"âš ï¸ {success_count}/{len(steps)} ë‹¨ê³„ë§Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
