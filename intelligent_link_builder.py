# ì§€ëŠ¥í˜• ë§í¬ ë¹Œë” ì‹œìŠ¤í…œ
# ì½˜í…ì¸  ë‚´ì— ë‚´ë¶€ë§í¬ì™€ ì™¸ë¶€ë§í¬ë¥¼ ìë™ìœ¼ë¡œ ì‚½ì…

import re
import random
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
from pbn_content_crawler import PBNContentCrawler
from improved_similarity_system import ImprovedSimilaritySystem


@dataclass
class LinkCandidate:
    """ë§í¬ í›„ë³´ ë°ì´í„° í´ë˜ìŠ¤"""

    text: str  # ì•µì»¤ í…ìŠ¤íŠ¸
    url: str  # ë§í¬ URL
    link_type: str  # 'internal' ë˜ëŠ” 'external'
    position: int  # ì½˜í…ì¸  ë‚´ ìœ„ì¹˜
    confidence: float  # ì‹ ë¢°ë„ ì ìˆ˜ (0-1)
    source: str  # ë§í¬ ì†ŒìŠ¤ ('client', 'pbn', 'external')


class IntelligentLinkBuilder:
    """ì§€ëŠ¥í˜• ë§í¬ ë¹Œë” í´ë˜ìŠ¤"""

    def __init__(self, crawler: PBNContentCrawler = None):
        """
        ë§í¬ ë¹Œë” ì´ˆê¸°í™”

        Args:
            crawler: PBN ì½˜í…ì¸  í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
        """
        self.crawler = crawler or PBNContentCrawler()
        self.similarity_system = ImprovedSimilaritySystem()  # ğŸ§  AI ê¸°ë°˜ ìœ ì‚¬ë„ ì‹œìŠ¤í…œ

        # ë§í¬ ì‚½ì… ì„¤ì •
        self.config = {
            "external_link_probability": 1.0,  # ì™¸ë¶€ë§í¬(í´ë¼ì´ì–¸íŠ¸) 100% í™•ë¥ 
            "internal_link_probability": 0.7,  # ë‚´ë¶€ë§í¬ 70% í™•ë¥ 
            "max_internal_links": 5,  # ìµœëŒ€ ë‚´ë¶€ë§í¬ ìˆ˜
            "max_external_links": 3,  # ìµœëŒ€ ì™¸ë¶€ë§í¬ ìˆ˜ (í´ë¼ì´ì–¸íŠ¸ ì œì™¸)
            "min_similarity_score": 0.3,  # ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜
            "link_density_limit": 0.03,  # ë§í¬ ë°€ë„ ì œí•œ (3%)
        }

        print("ğŸ”— ì§€ëŠ¥í˜• ë§í¬ ë¹Œë” ì´ˆê¸°í™” ì™„ë£Œ")

    def extract_keywords_from_content(
        self,
        content: str,
        main_keyword: str,
        lsi_keywords: List[str] = None,
        longtail_keywords: List[str] = None,
    ) -> List[str]:
        """
        ì½˜í…ì¸ ì—ì„œ ë§í¬ ê°€ëŠ¥í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œ

        Args:
            content: ë¶„ì„í•  ì½˜í…ì¸ 
            main_keyword: ë©”ì¸ í‚¤ì›Œë“œ
            lsi_keywords: LSI í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            longtail_keywords: ë¡±í…Œì¼ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        all_keywords = [main_keyword]

        if lsi_keywords:
            all_keywords.extend(lsi_keywords)

        if longtail_keywords:
            all_keywords.extend(longtail_keywords)

        # ì½˜í…ì¸ ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
        existing_keywords = []
        for keyword in all_keywords:
            if keyword.lower() in content.lower():
                existing_keywords.append(keyword)

        print(
            f"ğŸ“ ì½˜í…ì¸ ì—ì„œ {len(existing_keywords)}ê°œ í‚¤ì›Œë“œ ë°œê²¬: {existing_keywords}"
        )
        return existing_keywords

    def find_client_link_position(
        self, content: str, keyword: str
    ) -> Optional[Tuple[int, int, str]]:
        """
        í´ë¼ì´ì–¸íŠ¸ ë§í¬ë¥¼ ì‚½ì…í•  ìµœì ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            content: ê²€ìƒ‰í•  ì½˜í…ì¸ 
            keyword: ì•µì»¤í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  í‚¤ì›Œë“œ

        Returns:
            (ì‹œì‘ìœ„ì¹˜, ëìœ„ì¹˜, ë§¤ì¹­ëœí…ìŠ¤íŠ¸) ë˜ëŠ” None
        """
        # 1ìˆœìœ„: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        pattern = r"\b" + re.escape(keyword) + r"\b"
        match = re.search(pattern, content, re.IGNORECASE)

        if match:
            return (match.start(), match.end(), match.group())

        # 2ìˆœìœ„: í‚¤ì›Œë“œê°€ í¬í•¨ëœ êµ¬ë¬¸ ì°¾ê¸°
        keyword_parts = keyword.split()
        if len(keyword_parts) > 1:
            for part in keyword_parts:
                if len(part) > 2:  # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œì™¸
                    pattern = r"\b" + re.escape(part) + r"\b"
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        return (match.start(), match.end(), match.group())

        return None

    def insert_client_link(
        self, content: str, keyword: str, client_url: str
    ) -> Tuple[str, bool]:
        """
        í´ë¼ì´ì–¸íŠ¸ ë§í¬ë¥¼ ì½˜í…ì¸ ì— ì‚½ì… (100% í™•ë¥ )

        Args:
            content: ì›ë³¸ ì½˜í…ì¸ 
            keyword: ì•µì»¤í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
            client_url: í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ URL

        Returns:
            (ìˆ˜ì •ëœ ì½˜í…ì¸ , ì„±ê³µì—¬ë¶€)
        """
        print(f"ğŸ¯ í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì… ì‹œë„: '{keyword}' -> {client_url}")

        # ë§í¬ ì‚½ì… ìœ„ì¹˜ ì°¾ê¸°
        position = self.find_client_link_position(content, keyword)

        if position:
            start, end, matched_text = position

            # ì´ë¯¸ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            before_text = content[max(0, start - 10) : start]
            after_text = content[end : end + 10]

            if "<a " in before_text or "</a>" in after_text:
                print("   âš ï¸ ì´ë¯¸ ë§í¬ê°€ ìˆëŠ” ìœ„ì¹˜ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
                # ë‹¤ìŒ ë§¤ì¹­ ìœ„ì¹˜ ì°¾ê¸°
                remaining_content = content[end:]
                next_position = self.find_client_link_position(
                    remaining_content, keyword
                )
                if next_position:
                    start, end, matched_text = next_position
                    start += len(content[:end])  # ì˜¤í”„ì…‹ ì¡°ì •
                    end += len(content[:end])
                else:
                    # ê°•ì œ ì‚½ì…: ì½˜í…ì¸  ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€
                    print("   ğŸ”§ ê°•ì œ ì‚½ì…: ì½˜í…ì¸  ì‹œì‘ ë¶€ë¶„ì— ë§í¬ ì¶”ê°€")
                    link_html = f'<a href="{client_url}" target="_blank" rel="noopener">{keyword}</a>'
                    modified_content = link_html + " " + content
                    return modified_content, True

            # ë§í¬ HTML ìƒì„±
            link_html = f'<a href="{client_url}" target="_blank" rel="noopener">{matched_text}</a>'

            # ì½˜í…ì¸ ì— ë§í¬ ì‚½ì…
            modified_content = content[:start] + link_html + content[end:]

            print(f"   âœ… í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì… ì„±ê³µ: '{matched_text}'")
            return modified_content, True

        else:
            # í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê°•ì œ ì‚½ì…
            print(f"   ğŸ”§ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê°•ì œ ì‚½ì…: ì½˜í…ì¸  ì‹œì‘ ë¶€ë¶„")
            link_html = (
                f'<a href="{client_url}" target="_blank" rel="noopener">{keyword}</a>'
            )
            modified_content = link_html + " " + content
            return modified_content, True

    def find_internal_link_opportunities(
        self, content: str, keywords: List[str]
    ) -> List[Dict[str, Any]]:
        """
        ë‚´ë¶€ë§í¬ ì‚½ì… ê¸°íšŒë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            content: ë¶„ì„í•  ì½˜í…ì¸ 
            keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë‚´ë¶€ë§í¬ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” ë‚´ë¶€ë§í¬ ê¸°íšŒ íƒìƒ‰ ì¤‘... (í‚¤ì›Œë“œ: {len(keywords)}ê°œ)")

        # PBNì—ì„œ ìœ ì‚¬í•œ í¬ìŠ¤íŠ¸ ì°¾ê¸° (AI ê¸°ë°˜ FAISS ì‹œìŠ¤í…œ ì‚¬ìš©)
        similar_posts = self.similarity_system.find_similar_posts_fast(
            keywords,
            limit=self.config["max_internal_links"] * 2,  # ì—¬ìœ ìˆê²Œ ê°€ì ¸ì˜¤ê¸°
            min_similarity=self.config["min_similarity_score"],
            random_selection=True,  # ğŸ² ëœë¤ ì„ íƒìœ¼ë¡œ ì¤‘ë³µ ë§í¬ ë°©ì§€
        )

        if not similar_posts:
            print("   âŒ ìœ ì‚¬í•œ PBN í¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        print(f"   ğŸ“„ {len(similar_posts)}ê°œì˜ ìœ ì‚¬í•œ PBN í¬ìŠ¤íŠ¸ ë°œê²¬")

        # ë§í¬ í›„ë³´ ìƒì„±
        link_candidates = []

        for post in similar_posts:
            # ì½˜í…ì¸ ì—ì„œ ì´ í¬ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œ ì°¾ê¸°
            post_title = post["title"]
            post_url = post["url"]
            similarity_score = post.get("similarity_score", 0.5)

            # í¬ìŠ¤íŠ¸ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
            title_words = re.findall(r"\w+", post_title)
            potential_anchors = []

            # ì œëª©ì˜ ì£¼ìš” ë‹¨ì–´ë“¤ì„ ì•µì»¤í…ìŠ¤íŠ¸ í›„ë³´ë¡œ ì‚¬ìš©
            for word in title_words:
                if len(word) > 2 and word.lower() in content.lower():
                    potential_anchors.append(word)

            # ì›ë³¸ í‚¤ì›Œë“œë„ ì•µì»¤í…ìŠ¤íŠ¸ í›„ë³´ì— í¬í•¨
            for keyword in keywords:
                if keyword.lower() in content.lower():
                    potential_anchors.append(keyword)

            # ê°€ì¥ ì ì ˆí•œ ì•µì»¤í…ìŠ¤íŠ¸ ì„ íƒ
            if potential_anchors:
                # ê¸¸ì´ì™€ ê´€ë ¨ì„±ì„ ê³ ë ¤í•´ì„œ ì„ íƒ
                best_anchor = max(potential_anchors, key=lambda x: len(x))

                # ì½˜í…ì¸ ì—ì„œ ìœ„ì¹˜ ì°¾ê¸°
                pattern = r"\b" + re.escape(best_anchor) + r"\b"
                match = re.search(pattern, content, re.IGNORECASE)

                if match:
                    link_candidates.append(
                        {
                            "anchor_text": best_anchor,
                            "url": post_url,
                            "position": match.start(),
                            "confidence": similarity_score,
                            "post_title": post_title,
                            "site_url": post["site_url"],
                        }
                    )

        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        link_candidates.sort(key=lambda x: x["confidence"], reverse=True)

        print(f"   ğŸ”— {len(link_candidates)}ê°œì˜ ë‚´ë¶€ë§í¬ í›„ë³´ ìƒì„±")
        return link_candidates

    def insert_internal_links(
        self, content: str, link_candidates: List[Dict[str, Any]]
    ) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ë‚´ë¶€ë§í¬ë“¤ì„ ì½˜í…ì¸ ì— ì‚½ì…

        Args:
            content: ì›ë³¸ ì½˜í…ì¸ 
            link_candidates: ë§í¬ í›„ë³´ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ìˆ˜ì •ëœ ì½˜í…ì¸ , ì‚½ì…ëœ ë§í¬ ì •ë³´)
        """
        if not link_candidates:
            return content, []

        print(f"ğŸ”— ë‚´ë¶€ë§í¬ ì‚½ì… ì‹œì‘: {len(link_candidates)}ê°œ í›„ë³´")

        modified_content = content
        inserted_links = []
        offset = 0  # ì‚½ì…ìœ¼ë¡œ ì¸í•œ ìœ„ì¹˜ ì˜¤í”„ì…‹

        # ìœ„ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ì•ì—ì„œë¶€í„° ì‚½ì…)
        candidates_by_position = sorted(link_candidates, key=lambda x: x["position"])

        for i, candidate in enumerate(candidates_by_position):
            if len(inserted_links) >= self.config["max_internal_links"]:
                break

            # í™•ë¥ ì ìœ¼ë¡œ ë§í¬ ì‚½ì… ê²°ì •
            if random.random() > self.config["internal_link_probability"]:
                continue

            anchor_text = candidate["anchor_text"]
            url = candidate["url"]
            position = candidate["position"] + offset

            # ì´ë¯¸ ë§í¬ê°€ ìˆëŠ” ìœ„ì¹˜ì¸ì§€ í™•ì¸
            surrounding_text = modified_content[
                max(0, position - 20) : position + len(anchor_text) + 20
            ]
            if "<a " in surrounding_text and "</a>" in surrounding_text:
                print(f"   âš ï¸ ì´ë¯¸ ë§í¬ê°€ ìˆëŠ” ìœ„ì¹˜ ê±´ë„ˆëœ€: '{anchor_text}'")
                continue

            # ì •í™•í•œ ìœ„ì¹˜ì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸°
            pattern = r"\b" + re.escape(anchor_text) + r"\b"
            match = re.search(
                pattern, modified_content[position : position + 50], re.IGNORECASE
            )

            if match:
                actual_start = position + match.start()
                actual_end = position + match.end()
                actual_text = modified_content[actual_start:actual_end]

                # ë§í¬ HTML ìƒì„±
                link_html = (
                    f'<a href="{url}" target="_blank" rel="noopener">{actual_text}</a>'
                )

                # ì½˜í…ì¸ ì— ë§í¬ ì‚½ì…
                modified_content = (
                    modified_content[:actual_start]
                    + link_html
                    + modified_content[actual_end:]
                )

                # ì˜¤í”„ì…‹ ì—…ë°ì´íŠ¸
                offset += len(link_html) - len(actual_text)

                # ì‚½ì…ëœ ë§í¬ ì •ë³´ ê¸°ë¡
                inserted_links.append(
                    {
                        "anchor_text": actual_text,
                        "url": url,
                        "post_title": candidate["post_title"],
                        "site_url": candidate["site_url"],
                        "confidence": candidate["confidence"],
                    }
                )

                print(f"   âœ… ë‚´ë¶€ë§í¬ ì‚½ì…: '{actual_text}' -> {url}")

        print(f"ğŸ‰ ë‚´ë¶€ë§í¬ ì‚½ì… ì™„ë£Œ: {len(inserted_links)}ê°œ ì‚½ì…")
        return modified_content, inserted_links

    def add_additional_external_links(
        self, content: str, keywords: List[str]
    ) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ì¶”ê°€ ì™¸ë¶€ë§í¬ ì‚½ì… (ê¶Œìœ„ìˆëŠ” ì‚¬ì´íŠ¸ë“¤)

        Args:
            content: ì›ë³¸ ì½˜í…ì¸ 
            keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ìˆ˜ì •ëœ ì½˜í…ì¸ , ì‚½ì…ëœ ë§í¬ ì •ë³´)
        """
        # ê¶Œìœ„ìˆëŠ” ì‚¬ì´íŠ¸ë“¤ (ì˜ˆì‹œ)
        authoritative_sites = [
            {"domain": "wikipedia.org", "name": "ìœ„í‚¤í”¼ë””ì•„"},
            {"domain": "naver.com", "name": "ë„¤ì´ë²„"},
            {"domain": "google.com", "name": "êµ¬ê¸€"},
            {"domain": "tistory.com", "name": "í‹°ìŠ¤í† ë¦¬"},
            {"domain": "brunch.co.kr", "name": "ë¸ŒëŸ°ì¹˜"},
        ]

        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ êµ¬í˜„

        modified_content = content
        inserted_links = []

        # í™•ë¥ ì ìœ¼ë¡œ 1-2ê°œì˜ ì™¸ë¶€ë§í¬ ì¶”ê°€
        if random.random() < 0.5 and keywords:  # 50% í™•ë¥ 
            selected_keyword = random.choice(keywords)
            selected_site = random.choice(authoritative_sites)

            # ê°€ìƒì˜ URL ìƒì„± (ì‹¤ì œë¡œëŠ” ê²€ìƒ‰ API ë“±ì„ ì‚¬ìš©í•´ì•¼ í•¨)
            external_url = (
                f"https://{selected_site['domain']}/search?q={selected_keyword}"
            )

            # í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°
            pattern = r"\b" + re.escape(selected_keyword) + r"\b"
            matches = list(re.finditer(pattern, modified_content, re.IGNORECASE))

            if matches:
                # ë§ˆì§€ë§‰ ë§¤ì¹­ ìœ„ì¹˜ì— ë§í¬ ì‚½ì… (ì´ë¯¸ í´ë¼ì´ì–¸íŠ¸ ë§í¬ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë‚®ìŒ)
                match = matches[-1]
                start, end = match.start(), match.end()
                matched_text = match.group()

                # ì´ë¯¸ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                surrounding = modified_content[max(0, start - 10) : end + 10]
                if "<a " not in surrounding:
                    link_html = f'<a href="{external_url}" target="_blank" rel="noopener">{matched_text}</a>'
                    modified_content = (
                        modified_content[:start] + link_html + modified_content[end:]
                    )

                    inserted_links.append(
                        {
                            "anchor_text": matched_text,
                            "url": external_url,
                            "site_name": selected_site["name"],
                            "type": "external",
                        }
                    )

                    print(
                        f"   ğŸŒ ì™¸ë¶€ë§í¬ ì¶”ê°€: '{matched_text}' -> {selected_site['name']}"
                    )

        return modified_content, inserted_links

    def build_comprehensive_links(
        self,
        content: str,
        keyword: str,
        client_url: str,
        lsi_keywords: List[str] = None,
        longtail_keywords: List[str] = None,
    ) -> Dict[str, Any]:
        """
        ì¢…í•©ì ì¸ ë§í¬ ë¹Œë”© ìˆ˜í–‰

        Args:
            content: ì›ë³¸ ì½˜í…ì¸ 
            keyword: ë©”ì¸ í‚¤ì›Œë“œ
            client_url: í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ URL
            lsi_keywords: LSI í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            longtail_keywords: ë¡±í…Œì¼ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë§í¬ ë¹Œë”© ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("ğŸš€ ì¢…í•©ì ì¸ ë§í¬ ë¹Œë”© ì‹œì‘")
        print("=" * 50)

        modified_content = content
        link_report = {
            "client_link": None,
            "internal_links": [],
            "external_links": [],
            "total_links": 0,
            "success": False,
        }

        try:
            # 1. í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì… (100% í™•ë¥ )
            print("ğŸ¯ 1ë‹¨ê³„: í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì…")
            modified_content, client_success = self.insert_client_link(
                modified_content, keyword, client_url
            )

            if client_success:
                link_report["client_link"] = {
                    "keyword": keyword,
                    "url": client_url,
                    "type": "client",
                }
                print("   âœ… í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì… ì„±ê³µ")
            else:
                print("   âŒ í´ë¼ì´ì–¸íŠ¸ ë§í¬ ì‚½ì… ì‹¤íŒ¨")

            # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
            print("\nğŸ” 2ë‹¨ê³„: ë§í¬ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ì¶”ì¶œ")
            all_keywords = self.extract_keywords_from_content(
                modified_content, keyword, lsi_keywords, longtail_keywords
            )

            # 3. ë‚´ë¶€ë§í¬ ì‚½ì…
            print("\nğŸ”— 3ë‹¨ê³„: ë‚´ë¶€ë§í¬ ì‚½ì…")
            if all_keywords:
                link_candidates = self.find_internal_link_opportunities(
                    modified_content, all_keywords
                )

                if link_candidates:
                    modified_content, internal_links = self.insert_internal_links(
                        modified_content, link_candidates
                    )
                    link_report["internal_links"] = internal_links
                else:
                    print("   âŒ ë‚´ë¶€ë§í¬ í›„ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # 4. ì¶”ê°€ ì™¸ë¶€ë§í¬ ì‚½ì…
            print("\nğŸŒ 4ë‹¨ê³„: ì¶”ê°€ ì™¸ë¶€ë§í¬ ì‚½ì…")
            modified_content, external_links = self.add_additional_external_links(
                modified_content, all_keywords
            )
            link_report["external_links"] = external_links

            # 5. ìµœì¢… ê²°ê³¼ ê³„ì‚°
            link_report["total_links"] = (
                (1 if link_report["client_link"] else 0)
                + len(link_report["internal_links"])
                + len(link_report["external_links"])
            )
            link_report["success"] = link_report["total_links"] > 0

            # ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥
            print("\n" + "=" * 50)
            print("ğŸ‰ ë§í¬ ë¹Œë”© ì™„ë£Œ!")
            print(f"ğŸ“Š ì´ ì‚½ì…ëœ ë§í¬: {link_report['total_links']}ê°œ")
            print(f"   ğŸ¯ í´ë¼ì´ì–¸íŠ¸ ë§í¬: {1 if link_report['client_link'] else 0}ê°œ")
            print(f"   ğŸ”— ë‚´ë¶€ë§í¬: {len(link_report['internal_links'])}ê°œ")
            print(f"   ğŸŒ ì™¸ë¶€ë§í¬: {len(link_report['external_links'])}ê°œ")

            if link_report["internal_links"]:
                print("\nğŸ“‹ ì‚½ì…ëœ ë‚´ë¶€ë§í¬:")
                for link in link_report["internal_links"]:
                    print(f"   â€¢ '{link['anchor_text']}' -> {link['post_title']}")

            return {"content": modified_content, "report": link_report}

        except Exception as e:
            print(f"âŒ ë§í¬ ë¹Œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback

            traceback.print_exc()

            link_report["success"] = False
            link_report["error"] = str(e)

            return {"content": content, "report": link_report}  # ì›ë³¸ ì½˜í…ì¸  ë°˜í™˜


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_link_builder():
    """ë§í¬ ë¹Œë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë§í¬ ë¹Œë” í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_content = """
    <h1>ë°±ë§í¬ í…ŒìŠ¤íŠ¸ì˜ ì¤‘ìš”ì„±</h1>
    <p>ë°±ë§í¬ëŠ” SEOì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ê²€ìƒ‰ì—”ì§„ìµœì í™”ë¥¼ ìœ„í•´ì„œëŠ” ê³ í’ˆì§ˆì˜ ë°±ë§í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
    <p>ë°±ë§í¬ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì›¹ì‚¬ì´íŠ¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
    <h2>SEO ì „ëµ</h2>
    <p>íš¨ê³¼ì ì¸ SEO ì „ëµì—ëŠ” ë°±ë§í¬ êµ¬ì¶•ì´ í¬í•¨ë©ë‹ˆë‹¤.</p>
    """

    test_keyword = "ë°±ë§í¬ í…ŒìŠ¤íŠ¸"
    test_client_url = "https://example-client.com"
    test_lsi_keywords = ["SEO", "ê²€ìƒ‰ì—”ì§„ìµœì í™”", "ë§í¬ë¹Œë”©"]
    test_longtail_keywords = ["ë°±ë§í¬ í…ŒìŠ¤íŠ¸ ë°©ë²•", "SEO ë°±ë§í¬ ì „ëµ"]

    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (ì‹¤ì œ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •)
    crawler = PBNContentCrawler()
    link_builder = IntelligentLinkBuilder(crawler)

    # ë§í¬ ë¹Œë”© ì‹¤í–‰
    result = link_builder.build_comprehensive_links(
        test_content,
        test_keyword,
        test_client_url,
        test_lsi_keywords,
        test_longtail_keywords,
    )

    print("\nğŸ“„ ê²°ê³¼ ì½˜í…ì¸ :")
    print(result["content"])

    print("\nğŸ“Š ë§í¬ ë¹Œë”© ë³´ê³ ì„œ:")
    print(json.dumps(result["report"], indent=2, ensure_ascii=False))


if __name__ == "__main__":
    import json

    test_link_builder()
