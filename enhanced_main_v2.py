# v2.0 - ê³ ë„í™”ëœ PBN ë°±ë§í¬ ìë™í™” ì‹œìŠ¤í…œ
# ê¸°ì¡´ ì‹œìŠ¤í…œì˜ ëª¨ë“  ê¸°ëŠ¥ + ê³ í’ˆì§ˆ ì½˜í…ì¸  ìƒì„± ê¸°ëŠ¥ í†µí•©

import sys
import os
import time
import random
import re
import base64
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from openai import OpenAI
import requests
from PIL import Image
import ssl
import xmlrpc.client
from wordpress_xmlrpc import Client
from wordpress_xmlrpc.methods import media, posts
from wordpress_xmlrpc.compat import xmlrpc_client
from pathlib import Path
import io

# ê¸°ì¡´ ëª¨ë“ˆ import
from controlDB import (
    ControlDB,
    get_active_clients,
    get_client_keywords,
    get_random_keyword_for_client,
    update_client_info,
    move_client_to_completed,
    get_all_pbn_sites,
    get_random_pbn_site,
    add_post,
    view_client_status,
    add_pbn_site,
    view_pbn_sites,
    delete_record_by_id,
    add_client,
    view_clients,
    view_completed_clients,
    pause_client,
    resume_client,
    pause_all_clients,
    resume_all_clients,
    fetch_all_posts,
    save_all_backlinks_to_excel,
    show_all_tables,
    add_client_keyword,
    remove_duplicate_clients,
)
from wordpress_functions import WordPressManager

# ê³ ë„í™”ëœ RAG íŒŒì´í”„ë¼ì¸ import
import asyncio
import json
from pathlib import Path
from typing import Tuple, List, Dict, Any, Optional
from langchain_core.messages import HumanMessage

# HTML ë³€í™˜ ëª¨ë“ˆ import
from src.generators.html.simple_html_converter import SimpleHTMLConverter

# ìƒˆë¡œìš´ ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ import
from pbn_content_crawler import PBNContentCrawler
from intelligent_link_builder import IntelligentLinkBuilder
from improved_similarity_system import ImprovedSimilaritySystem

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_DALLE_API_KEY")
client = OpenAI(api_key=api_key)


def insert_anchor_text(content: str, keyword: str, client_site_url: str) -> str:
    """
    [DEPRECATED] ê¸°ì¡´ ë‹¨ìˆœ ì•µì»¤ í…ìŠ¤íŠ¸ ì‚½ì… í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„±ìš©)
    ìƒˆë¡œìš´ ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    anchor = f'<a href="{client_site_url}" target="_blank" rel="noopener">{keyword}</a>'
    pattern = r"\b" + re.escape(keyword) + r"\b"
    new_content, count = re.subn(pattern, anchor, content, count=1, flags=re.IGNORECASE)
    if count == 0:
        new_content = anchor + " " + content
    return new_content


def input_with_validation(
    prompt,
    validation_func=lambda x: True,
    error_message="ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.",
):
    """ì…ë ¥ ê°’ì„ ê²€ì¦í•˜ê³  ìœ íš¨í•œ ê°’ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    while True:
        value = input(prompt).strip()
        if validation_func(value):
            return value
        else:
            print(error_message)


def is_positive_int(x):
    return x.isdigit() and int(x) > 0


class ImageOptimizer:
    """ì´ë¯¸ì§€ ìµœì í™” í´ë˜ìŠ¤"""

    def __init__(self):
        self.supported_formats = ["PNG", "JPEG", "WEBP"]

    def optimize_for_web(
        self,
        image_path: Path,
        max_size: tuple = (512, 512),
        target_file_size_kb: int = 50,
        quality_range: tuple = (70, 90),
    ) -> Dict[str, Any]:
        """
        ì›¹ìš© ì´ë¯¸ì§€ ìµœì í™”

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            max_size: ìµœëŒ€ í¬ê¸° (width, height)
            target_file_size_kb: ëª©í‘œ íŒŒì¼ í¬ê¸° (KB)
            quality_range: í’ˆì§ˆ ë²”ìœ„ (min, max)

        Returns:
            ìµœì í™” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            original_size = image_path.stat().st_size
            original_size_kb = original_size / 1024

            # ì´ë¯¸ì§€ ì—´ê¸°
            with Image.open(image_path) as img:
                # RGBë¡œ ë³€í™˜ (PNGëŠ” íˆ¬ëª…ë„ ì§€ì›í•˜ë¯€ë¡œ)
                if img.mode in ("RGBA", "LA"):
                    # íˆ¬ëª… ë°°ê²½ì„ í°ìƒ‰ìœ¼ë¡œ ë³€í™˜
                    background = Image.new("RGB", img.size, (255, 255, 255))
                    if img.mode == "RGBA":
                        background.paste(img, mask=img.split()[-1])
                    else:
                        background.paste(img)
                    img = background
                elif img.mode != "RGB":
                    img = img.convert("RGB")

                # í¬ê¸° ì¡°ì •
                img.thumbnail(max_size, Image.Resampling.LANCZOS)

                # PNGë¡œ ì €ì¥ (ì›ë³¸ í˜•ì‹ ìœ ì§€)
                img.save(image_path, "PNG", optimize=True)

            # ìµœì¢… í¬ê¸° í™•ì¸
            final_size = image_path.stat().st_size
            final_size_kb = final_size / 1024
            reduction_percent = (
                (original_size_kb - final_size_kb) / original_size_kb
            ) * 100

            return {
                "success": True,
                "original_size_kb": round(original_size_kb, 2),
                "final_size_kb": round(final_size_kb, 2),
                "size_reduction_percent": round(reduction_percent, 2),
                "file_size_change": f"{original_size_kb:.1f}KB â†’ {final_size_kb:.1f}KB",
            }

        except Exception as e:
            return {"success": False, "error": str(e)}


class EnhancedPBNSystem:
    """ê³ ë„í™”ëœ PBN ë°±ë§í¬ ìë™í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.db = ControlDB()
        self.wp_manager = WordPressManager()
        self.html_converter = SimpleHTMLConverter()

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì´ë¯¸ì§€ ìƒì„±ìš©)
        load_dotenv()
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # ì´ë¯¸ì§€ ê´€ë ¨ ì´ˆê¸°í™”
        self.image_optimizer = ImageOptimizer()
        self.cost_tracker = {"total_images": 0, "image_details": []}

        # ìƒˆë¡œìš´ ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸ”— ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.pbn_crawler = PBNContentCrawler()

        # ğŸ§  AI ê¸°ë°˜ ìœ ì‚¬ë„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì•ˆì „í•œ ë°©ì‹)
        try:
            print("   ğŸ¤– AI ìœ ì‚¬ë„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            self.similarity_system = ImprovedSimilaritySystem()
            print("   âœ… AI ìœ ì‚¬ë„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

            # ì´ˆê¸°í™” í›„ ìƒíƒœ í™•ì¸
            print(
                f"   ğŸ” ì´ˆê¸°í™” í™•ì¸ - faiss_index: {self.similarity_system.faiss_index is not None}"
            )
            print(
                f"   ğŸ” ì´ˆê¸°í™” í™•ì¸ - similarity_model: {self.similarity_system.similarity_model is not None}"
            )
            print(
                f"   ğŸ” ì´ˆê¸°í™” í™•ì¸ - post_metadata: {len(self.similarity_system.post_metadata) if self.similarity_system.post_metadata else 0}ê°œ"
            )

        except Exception as e:
            print(f"   âš ï¸ AI ìœ ì‚¬ë„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("   ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
            import traceback

            traceback.print_exc()
            print("   ğŸ”„ ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            self.similarity_system = None

        self.link_builder = IntelligentLinkBuilder(self.pbn_crawler)

        # ê³ ë„í™”ëœ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.llm = client  # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.cost_tracker = {
            "total_calls": 0,
            "total_tokens": {"prompt": 0, "completion": 0},
            "total_duration": 0,
            "total_images": 0,
            "step_details": [],
            "image_details": [],
        }

        # ë””ë²„ê¹…ìš© ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.debug_dir = Path("data")
        self.debug_dir.mkdir(exist_ok=True)

        # í˜„ì¬ ì„¸ì…˜ìš© íƒ€ì„ìŠ¤íƒ¬í”„
        self.session_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        print("ğŸš€ ê³ ë„í™”ëœ PBN ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 50)

    def _safe_fragment(self, text: str, max_len: int = 120) -> str:
        """ìœˆë„ìš° í˜¸í™˜ íŒŒì¼ëª… ì¡°ê° ìƒì„± (ê¸ˆì§€ë¬¸ì ì œê±°/ì¹˜í™˜)"""
        import re

        frag = re.sub(r"[\\/:*?\"<>|]", "_", text)
        frag = re.sub(r"\s+", "_", frag)
        frag = frag.strip("._")
        if not frag:
            frag = "output"
        return frag[:max_len]

    def convert_to_blog_html_structure(
        self, html_content: str, sections: List[Dict]
    ) -> str:
        """HTMLì„ original_html êµ¬ì¡°ë¡œ ë³€í™˜ (fs- í”„ë¦¬í”½ìŠ¤ í´ë˜ìŠ¤ ì‚¬ìš©)"""
        import re

        # 1. ê¸°ë³¸ article êµ¬ì¡°ë¡œ ê°ì‹¸ê¸° (ì´ë¯¸ articleì´ ìˆìœ¼ë©´ ê°ì‹¸ì§€ ì•ŠìŒ)
        if "<article" not in html_content:
            original_html = f'<article class="fs-article">\n{html_content}\n</article>'
        else:
            original_html = html_content

        # 2. ëª©ì°¨ ì„¹ì…˜ì„ nav íƒœê·¸ë¡œ ë³€í™˜ (ë” ê°„ê²°í•˜ê²Œ)
        original_html = self._convert_toc_to_nav_simple(original_html)

        # 3. ìš©ì–´ ì •ë¦¬ ì„¹ì…˜ ë³€í™˜
        original_html = self._convert_terms_section_structure(original_html)

        # 4. divë¥¼ sectionìœ¼ë¡œ ë³€í™˜ (fs- í´ë˜ìŠ¤ ì ìš©)
        original_html = re.sub(
            r"<div[^>]*>", '<section class="fs-section">', original_html
        )
        original_html = re.sub(r"</div>", "</section>", original_html)

        # 5. ì œëª© íƒœê·¸ì— í´ë˜ìŠ¤ ì¶”ê°€ (ë” ê°„ê²°í•˜ê²Œ)
        original_html = self._add_heading_classes_simple(original_html)

        # 6. ëª©ë¡ì— í´ë˜ìŠ¤ ì¶”ê°€
        original_html = self._add_list_classes(original_html)

        # 7. í…Œì´ë¸”ì— í´ë˜ìŠ¤ ì¶”ê°€
        original_html = self._add_table_classes(original_html)

        # 8. íŠ¹ë³„í•œ ì„¹ì…˜ í´ë˜ìŠ¤ ì¶”ê°€
        original_html = self._add_special_section_classes(original_html)

        # 9. HTML ì •ë¦¬
        original_html = self._cleanup_blog_html(original_html)

        return original_html

    def _convert_toc_to_nav(self, content: str) -> str:
        """ëª©ì°¨ ì„¹ì…˜ì„ nav íƒœê·¸ë¡œ ë³€í™˜"""
        toc_pattern = r'<h2[^>]*id="toc-section"[^>]*>\[ëª©ì°¨\](.*?)</h2>'
        toc_replacement = r'<nav class="fs-toc">\n<h2 id="toc-section" class="fs-h2">ëª©ì°¨</h2>\n\1\n</nav>'
        return re.sub(toc_pattern, toc_replacement, content, flags=re.DOTALL)

    def _convert_toc_to_nav_simple(self, content: str) -> str:
        """ëª©ì°¨ ì„¹ì…˜ì„ nav íƒœê·¸ë¡œ ë³€í™˜ (ê°„ê²°í•œ ë²„ì „)"""
        toc_pattern = r'<h2[^>]*id="toc-section"[^>]*>\[ëª©ì°¨\](.*?)</h2>'
        toc_replacement = (
            r'<nav class="fs-toc">\n<h2 class="fs-h2">ëª©ì°¨</h2>\n\1\n</nav>'
        )
        return re.sub(toc_pattern, toc_replacement, content, flags=re.DOTALL)

    def _convert_terms_section_structure(self, content: str) -> str:
        """ìš©ì–´ ì •ë¦¬ ì„¹ì…˜ êµ¬ì¡° ë³€í™˜"""
        # ìš©ì–´ ì •ë¦¬ ì„¹ì…˜ ë³€í™˜
        terms_pattern = r'<h2[^>]*id="í•µì‹¬-ìš©ì–´-ì •ë¦¬"[^>]*>\[ìš©ì–´\](.*?)</h2>'
        terms_replacement = r'<h2 id="í•µì‹¬-ìš©ì–´-ì •ë¦¬" class="fs-h2">í•µì‹¬ ìš©ì–´ ì •ë¦¬</h2>'
        content = re.sub(terms_pattern, terms_replacement, content, flags=re.DOTALL)

        # ìš©ì–´ ì •ì˜ ë¦¬ìŠ¤íŠ¸ì— í´ë˜ìŠ¤ ì¶”ê°€
        content = re.sub(r"<dl[^>]*>", '<dl class="fs-terms">', content)
        content = re.sub(r"<dt[^>]*>", '<dt class="fs-term-name">', content)
        content = re.sub(r"<dd[^>]*>", '<dd class="fs-term-description">', content)

        return content

    def _add_heading_classes(self, content: str) -> str:
        """ì œëª© íƒœê·¸ì— í´ë˜ìŠ¤ ì¶”ê°€ (ì¤‘ë³µ í´ë˜ìŠ¤ ë°©ì§€)"""
        # ê¸°ì¡´ í´ë˜ìŠ¤ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ìƒˆë¡œ ì¶”ê°€
        content = re.sub(r'<h1[^>]*class="[^"]*"[^>]*>', "<h1>", content)
        content = re.sub(r'<h2[^>]*class="[^"]*"[^>]*>', "<h2>", content)
        content = re.sub(r'<h3[^>]*class="[^"]*"[^>]*>', "<h3>", content)
        content = re.sub(r'<h4[^>]*class="[^"]*"[^>]*>', "<h4>", content)

        # fs- í´ë˜ìŠ¤ ì¶”ê°€
        content = re.sub(r"<h1([^>]*)>", r'<h1\1 class="fs-h1">', content)
        content = re.sub(r"<h2([^>]*)>", r'<h2\1 class="fs-h2">', content)
        content = re.sub(r"<h3([^>]*)>", r'<h3\1 class="fs-h3">', content)
        content = re.sub(r"<h4([^>]*)>", r'<h4\1 class="fs-h4">', content)

        return content

    def _add_heading_classes_simple(self, content: str) -> str:
        """ì œëª© íƒœê·¸ì— í´ë˜ìŠ¤ ì¶”ê°€ (ê°„ê²°í•œ ë²„ì „)"""
        # fs- í´ë˜ìŠ¤ ì§ì ‘ ì¶”ê°€ (ê¸°ì¡´ í´ë˜ìŠ¤ ê³ ë ¤í•˜ì§€ ì•ŠìŒ)
        content = re.sub(r"<h1([^>]*)>", r'<h1 class="fs-h1">', content)
        content = re.sub(r"<h2([^>]*)>", r'<h2 class="fs-h2">', content)
        content = re.sub(r"<h3([^>]*)>", r'<h3 class="fs-h3">', content)
        content = re.sub(r"<h4([^>]*)>", r'<h4 class="fs-h4">', content)

        return content

    def _add_list_classes(self, content: str) -> str:
        """ëª©ë¡ì— í´ë˜ìŠ¤ ì¶”ê°€"""
        content = re.sub(r"<ul[^>]*>", '<ul class="fs-list">', content)
        content = re.sub(r"<ol[^>]*>", '<ol class="fs-toc-list">', content)
        content = re.sub(r"<li[^>]*>", '<li class="fs-list-item">', content)
        return content

    def _add_table_classes(self, content: str) -> str:
        """í…Œì´ë¸”ì— í´ë˜ìŠ¤ ì¶”ê°€"""
        content = re.sub(r"<table[^>]*>", '<table class="fs-table">', content)
        content = re.sub(r"<thead[^>]*>", "<thead>", content)
        content = re.sub(r"<tbody[^>]*>", "<tbody>", content)
        content = re.sub(r"<tr[^>]*>", "<tr>", content)
        content = re.sub(r"<th[^>]*>", '<th class="fs-table-header">', content)
        content = re.sub(r"<td[^>]*>", '<td class="fs-table-cell">', content)
        return content

    def _add_special_section_classes(self, content: str) -> str:
        """íŠ¹ë³„í•œ ì„¹ì…˜ì— í´ë˜ìŠ¤ ì¶”ê°€"""
        # ê°œìš” ì„¹ì…˜
        content = re.sub(
            r'<section class="fs-section">\s*<h2[^>]*id="ê°œìš”"',
            '<section class="fs-section fs-intro">\n<h2 id="ê°œìš”"',
            content,
        )
        # ìš”ì•½ê³¼ ê²°ë¡  ì„¹ì…˜
        content = re.sub(
            r'<section class="fs-section">\s*<h2[^>]*id="ìš”ì•½ê³¼-ê²°ë¡ "',
            '<section class="fs-section fs-conclusion">\n<h2 id="ìš”ì•½ê³¼-ê²°ë¡ "',
            content,
        )
        # FAQ ì„¹ì…˜
        content = re.sub(
            r'<section class="fs-section">\s*<h2[^>]*id="ìì£¼-ë¬»ëŠ”-ì§ˆë¬¸"',
            '<section class="fs-section fs-faq">\n<h2 id="ìì£¼-ë¬»ëŠ”-ì§ˆë¬¸"',
            content,
        )
        return content

    def _cleanup_blog_html(self, content: str) -> str:
        """HTML ì •ë¦¬ ì‘ì—…"""
        # ì—°ì†ëœ ë¹ˆ ì¤„ ì œê±°
        content = re.sub(r"\n\s*\n\s*\n", "\n\n", content)
        # ì‹œì‘ê³¼ ë ê³µë°± ì œê±°
        content = content.strip()
        return content

    def save_debug_data(
        self, keyword: str, step: str, data: Any, file_extension: str = "json"
    ):
        """ë””ë²„ê¹…ìš© ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            safe_keyword = self._safe_fragment(keyword)
            filename = (
                f"{safe_keyword}_{step}_{self.session_timestamp}.{file_extension}"
            )
            filepath = self.debug_dir / filename

            if file_extension == "json":
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            elif file_extension == "md":
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(data)
            elif file_extension == "html":
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(data)
            else:
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(str(data))

            print(f"ğŸ’¾ ë””ë²„ê¹… ë°ì´í„° ì €ì¥: {filepath}")
            return filepath
        except Exception as e:
            print(f"âŒ ë””ë²„ê¹… ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def check_content_size(self, content: str, max_chars: int = 100000) -> bool:
        """ì½˜í…ì¸  í¬ê¸° ê²€ì‚¬ (ì›Œë“œí”„ë ˆìŠ¤ ì œí•œ ê³ ë ¤)"""
        char_count = len(content)
        word_count = len(content.split())

        print(f"ğŸ“Š ì½˜í…ì¸  í¬ê¸° ë¶„ì„:")
        print(f"   ğŸ“ ë¬¸ì ìˆ˜: {char_count:,}")
        print(f"   ğŸ“ ë‹¨ì–´ ìˆ˜: {word_count:,}")
        print(f"   ğŸ“ ì œí•œ: {max_chars:,} ë¬¸ì")

        if char_count > max_chars:
            print(f"âš ï¸ ì½˜í…ì¸ ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤! ({char_count:,} > {max_chars:,})")
            return False
        else:
            print(f"âœ… ì½˜í…ì¸  í¬ê¸° ì ì ˆí•¨")
            return True

    def _truncate_content(self, content: str, max_chars: int) -> str:
        """ì½˜í…ì¸ ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ì¶•ì†Œ (HTML íƒœê·¸ ê³ ë ¤)"""
        if len(content) <= max_chars:
            return content

        # HTML íƒœê·¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì•ˆì „í•˜ê²Œ ìë¥´ê¸°
        truncated = content[:max_chars]

        # ë§ˆì§€ë§‰ ì™„ì „í•œ íƒœê·¸ë¥¼ ì°¾ì•„ì„œ ìë¥´ê¸°
        last_tag_end = truncated.rfind(">")
        if last_tag_end > max_chars * 0.8:  # 80% ì´ìƒì´ë©´ íƒœê·¸ë¡œ ëë‚´ê¸°
            truncated = truncated[: last_tag_end + 1]

        # ë§ˆì§€ë§‰ ë¬¸ë‹¨ì„ ì™„ì„±í•˜ê¸° ìœ„í•´ "..." ì¶”ê°€
        truncated += "\n\n<p>...</p>"

        return truncated

    def _clean_content_for_wordpress(self, content: str) -> str:
        """ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œë¥¼ ìœ„í•œ ì½˜í…ì¸  ì •ë¦¬"""
        import re

        print("ğŸ§¹ ì›Œë“œí”„ë ˆìŠ¤ìš© ì½˜í…ì¸  ì •ë¦¬ ì¤‘...")

        # 1. ë³µì¡í•œ CSS í´ë˜ìŠ¤ ì œê±°í•˜ê³  ê¸°ë³¸ HTMLë¡œ ë³€í™˜
        # fs-article, fs-section ë“±ì˜ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì œê±°
        content = re.sub(r'class="[^"]*fs-[^"]*"', "", content)
        content = re.sub(r'class=""', "", content)

        # 2. ë¶ˆí•„ìš”í•œ article, nav íƒœê·¸ë¥¼ divë¡œ ë³€í™˜
        content = re.sub(r"<article[^>]*>", "<div>", content)
        content = re.sub(r"</article>", "</div>", content)
        content = re.sub(r"<nav[^>]*>", "<div>", content)
        content = re.sub(r"</nav>", "</div>", content)

        # 3. sectionì„ divë¡œ ë³€í™˜
        content = re.sub(r"<section[^>]*>", "<div>", content)
        content = re.sub(r"</section>", "</div>", content)

        # 4. ë³µì¡í•œ ëª©ì°¨ êµ¬ì¡° ë‹¨ìˆœí™”
        content = re.sub(r'<ol class="[^"]*">', "<ol>", content)
        content = re.sub(r'<dl class="[^"]*">', "<dl>", content)
        content = re.sub(r'<dt class="[^"]*">', "<dt>", content)
        content = re.sub(r'<dd class="[^"]*">', "<dd>", content)

        # 5. í…Œì´ë¸” í´ë˜ìŠ¤ ì œê±°
        content = re.sub(r'<table class="[^"]*">', "<table>", content)
        content = re.sub(r'<th class="[^"]*">', "<th>", content)
        content = re.sub(r'<td class="[^"]*">', "<td>", content)

        # 6. ë¹ˆ class ì†ì„± ì œê±°
        content = re.sub(r'\s+class=""', "", content)

        # 7. ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
        content = re.sub(r"\s+", " ", content)
        content = re.sub(r">\s+<", "><", content)

        # 8. íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ (ì¼ë¶€ ì´ëª¨ì§€ ì œê±° ë˜ëŠ” ëŒ€ì²´)
        emoji_replacements = {
            "ğŸ“š": "[ëª©ì°¨]",
            "ğŸ“–": "[ìš©ì–´]",
            "ğŸ”„": "",
            "âœ…": "",
            "âŒ": "",
            "âš ï¸": "[ì£¼ì˜]",
            "ğŸ¯": "[í•µì‹¬]",
            "ğŸ’¡": "[íŒ]",
            "ğŸš€": "",
            "ğŸ“Š": "[í†µê³„]",
            "ğŸ”": "[ë¶„ì„]",
            "ğŸ“ˆ": "[ì„±ì¥]",
            "ğŸ’¼": "[ë¹„ì¦ˆë‹ˆìŠ¤]",
        }

        for emoji, replacement in emoji_replacements.items():
            content = content.replace(emoji, replacement)

        # 9. ì¤„ë°”ê¿ˆ ì •ë¦¬
        content = re.sub(r"\n\s*\n\s*\n", "\n\n", content)

        print(f"âœ… ì½˜í…ì¸  ì •ë¦¬ ì™„ë£Œ (í¬ê¸°: {len(content)} ë°”ì´íŠ¸)")
        return content.strip()

    def _create_simple_html_content(self, content_data: dict) -> str:
        """ë§¤ìš° ê°„ë‹¨í•œ HTML í˜•íƒœë¡œ ì½˜í…ì¸  ìƒì„± (í˜¸í™˜ì„± ìµœìš°ì„ )"""
        print("ğŸ”§ ê°„ë‹¨í•œ HTML ì½˜í…ì¸  ìƒì„± ì¤‘...")

        html_parts = []

        # ì œëª©
        html_parts.append(f"<h1>{content_data['title']}</h1>")

        # Markdown ì½˜í…ì¸ ë¥¼ ê¸°ë³¸ HTMLë¡œ ë³€í™˜
        md_content = content_data["content"]

        # ê¸°ë³¸ì ì¸ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
        import re

        # í—¤ë”© ë³€í™˜
        md_content = re.sub(
            r"^### (.+)$", r"<h3>\1</h3>", md_content, flags=re.MULTILINE
        )
        md_content = re.sub(
            r"^## (.+)$", r"<h2>\1</h2>", md_content, flags=re.MULTILINE
        )
        md_content = re.sub(r"^# (.+)$", r"<h1>\1</h1>", md_content, flags=re.MULTILINE)

        # ë³¼ë“œ/ì´íƒ¤ë¦­ ë³€í™˜
        md_content = re.sub(r"\*\*(.+?)\*\*", r"<strong>\1</strong>", md_content)
        md_content = re.sub(r"\*(.+?)\*", r"<em>\1</em>", md_content)

        # ë§í¬ ë³€í™˜
        md_content = re.sub(r"\[(.+?)\]\((.+?)\)", r'<a href="\2">\1</a>', md_content)

        # ë¬¸ë‹¨ ë³€í™˜ (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ë¥¼ p íƒœê·¸ë¡œ)
        paragraphs = md_content.split("\n\n")
        html_paragraphs = []

        for para in paragraphs:
            para = para.strip()
            if para:
                # ì´ë¯¸ HTML íƒœê·¸ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if para.startswith("<"):
                    html_paragraphs.append(para)
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” p íƒœê·¸ë¡œ ê°ì‹¸ê¸°
                    html_paragraphs.append(f"<p>{para}</p>")

        html_parts.extend(html_paragraphs)

        simple_html = "\n\n".join(html_parts)

        # ì´ëª¨ì§€ ì œê±°
        emoji_pattern = re.compile(
            "["
            "\U0001f600-\U0001f64f"  # emoticons
            "\U0001f300-\U0001f5ff"  # symbols & pictographs
            "\U0001f680-\U0001f6ff"  # transport & map symbols
            "\U0001f1e0-\U0001f1ff"  # flags (iOS)
            "]+",
            flags=re.UNICODE,
        )

        simple_html = emoji_pattern.sub("", simple_html)

        print(f"âœ… ê°„ë‹¨í•œ HTML ìƒì„± ì™„ë£Œ (í¬ê¸°: {len(simple_html)} ë°”ì´íŠ¸)")
        return simple_html

    def _try_posting_with_retry(
        self,
        content,
        post_content,
        keyword,
        client_id,
        client_name,
        client_site_url,
        current_pbn_site=None,
    ):
        """PBN ì‚¬ì´íŠ¸ì— í¬ìŠ¤íŒ… ì‹œë„ (ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ëœë¤ ì‚¬ì´íŠ¸ì—ì„œ 1ë²ˆ ì¬ì‹œë„)"""
        from controlDB import get_all_pbn_sites, add_post
        import time
        import random

        print("ğŸ”„ PBN ì‚¬ì´íŠ¸ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        all_pbn_sites = get_all_pbn_sites()

        if not all_pbn_sites:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ PBN ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ì•± íŒ¨ìŠ¤ì›Œë“œê°€ ìˆëŠ” ì‚¬ì´íŠ¸ë§Œ í•„í„°ë§
        valid_pbn_sites = [
            site for site in all_pbn_sites if site[4]
        ]  # site[4] = app_password

        if not valid_pbn_sites:
            print("âŒ ì•± íŒ¨ìŠ¤ì›Œë“œê°€ ì„¤ì •ëœ PBN ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # 1ì°¨ ì‹œë„: í˜„ì¬ PBN ì‚¬ì´íŠ¸ ë˜ëŠ” ëœë¤ ì„ íƒ
        if current_pbn_site and current_pbn_site in valid_pbn_sites:
            first_attempt_site = current_pbn_site
        else:
            first_attempt_site = random.choice(valid_pbn_sites)

        print(f"ğŸ¯ 1ì°¨ ì‹œë„ PBN ì‚¬ì´íŠ¸: {first_attempt_site[1]}")

        success = self._try_single_pbn_posting(
            first_attempt_site,
            content,
            post_content,
            keyword,
            client_id,
            client_name,
            client_site_url,
        )

        if success:
            return True

        # 2ì°¨ ì‹œë„: ë‹¤ë¥¸ ëœë¤ PBN ì‚¬ì´íŠ¸ ì„ íƒ
        remaining_sites = [
            site for site in valid_pbn_sites if site[0] != first_attempt_site[0]
        ]

        if not remaining_sites:
            print("âŒ ì¬ì‹œë„í•  ë‹¤ë¥¸ PBN ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        second_attempt_site = random.choice(remaining_sites)
        print(f"ğŸ”„ 2ì°¨ ì‹œë„ PBN ì‚¬ì´íŠ¸: {second_attempt_site[1]}")

        success = self._try_single_pbn_posting(
            second_attempt_site,
            content,
            post_content,
            keyword,
            client_id,
            client_name,
            client_site_url,
        )

        if success:
            return True
        else:
            print("ğŸ’¥ 2ë²ˆì˜ PBN ì‚¬ì´íŠ¸ ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨")
            return False

    def _try_single_pbn_posting(
        self,
        pbn_site,
        content,
        post_content,
        keyword,
        client_id,
        client_name,
        client_site_url,
    ):
        """ë‹¨ì¼ PBN ì‚¬ì´íŠ¸ì—ì„œ í¬ìŠ¤íŒ… ì‹œë„"""
        from controlDB import add_post
        import time

        pbn_site_id, pbn_url, pbn_user, pbn_pass, pbn_app_pass = pbn_site

        try:
            print(f"   ğŸ“¤ í¬ìŠ¤íŒ… ì‹œë„ ì¤‘... (ì‚¬ìš©ì: {pbn_user})")

            # ì›Œë“œí”„ë ˆìŠ¤ì— í¬ìŠ¤íŒ…
            success = self.wp_manager.create_post(
                site_url=pbn_url,
                username=pbn_user,
                app_password=pbn_app_pass,
                title=content["title"],
                content=post_content,
                status="publish",
            )

            if success:
                print(f"   âœ… í¬ìŠ¤íŒ… ì„±ê³µ: {pbn_url}")
                print(f"   ğŸ“ ìƒì„±ëœ í¬ìŠ¤íŠ¸ ID: {success}")

                # DBì— í¬ìŠ¤íŠ¸ ê¸°ë¡
                post_url = f"{pbn_url}/?p={success}"
                add_post(
                    client_id,
                    client_name,
                    client_site_url,
                    keyword,
                    post_url,
                )
                print(f"   ğŸ’¾ í¬ìŠ¤íŠ¸ ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {post_url}")
                print(f"ğŸ‰ {client_name}ì— ëŒ€í•œ í¬ìŠ¤íŒ… ì™„ë£Œ!")
                time.sleep(10)
                return True
            else:
                print(f"   âŒ í¬ìŠ¤íŒ… ì‹¤íŒ¨: {pbn_url}")
                return False

        except Exception as e:
            print(f"   âŒ í¬ìŠ¤íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def track_llm_call(
        self,
        step_name: str,
        prompt_tokens: int,
        completion_tokens: int,
        duration: float,
        output: str,
        purpose: str,
    ):
        """LLM í˜¸ì¶œ ì¶”ì """
        self.cost_tracker["total_calls"] += 1
        self.cost_tracker["total_tokens"]["prompt"] += prompt_tokens
        self.cost_tracker["total_tokens"]["completion"] += completion_tokens
        self.cost_tracker["total_duration"] += duration

        # GPT-4 ë¹„ìš© ê³„ì‚° (ì¶”ì •)
        input_cost_per_1k = 0.00003  # $0.03 per 1K tokens
        output_cost_per_1k = 0.00006  # $0.06 per 1K tokens

        step_cost = (prompt_tokens * input_cost_per_1k / 1000) + (
            completion_tokens * output_cost_per_1k / 1000
        )

        self.cost_tracker["step_details"].append(
            {
                "step": step_name,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "duration_seconds": duration,
                "tokens": {"prompt": prompt_tokens, "completion": completion_tokens},
                "estimated_cost_usd": step_cost,
                "purpose": purpose,
                "output_summary": output[:100] + "..." if len(output) > 100 else output,
            }
        )

    def load_active_clients_and_log(self):
        """í™œì„± í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¡°íšŒí•˜ê³ , ëª©ë¡ì„ ì¶œë ¥í•œ í›„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        active_clients = get_active_clients()
        if not active_clients:
            print("í˜„ì¬ í™œì„±í™”ëœ í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        print("==== [ì‘ì—… ëŒ€ìƒ í´ë¼ì´ì–¸íŠ¸ ëª©ë¡] ====")
        for c in active_clients:
            (
                client_id,
                client_name,
                client_site_url,
                _,
                remain_days,
                _,
                _,
                daily_min,
                daily_max,
            ) = c
            print(f"[í´ë¼ì´ì–¸íŠ¸ID: {client_id}] {client_name}")
            print(f" â”” URL: {client_site_url}")
            print(
                f" â”” ë‚¨ì€ ì¼ìˆ˜: {remain_days}, ìµœì†Œ/ìµœëŒ€ ë§í¬: {daily_min}/{daily_max}\n"
            )
        return active_clients

    def prepare_day_list(self, clients):
        """
        í´ë¼ì´ì–¸íŠ¸ë³„ ì˜¤ëŠ˜ ì‘ì—… íšŸìˆ˜ë¥¼ ê²°ì •í•˜ì—¬ day_listë¥¼ êµ¬ì„±í•˜ê³ ,
        ì—…ë°ì´íŠ¸ ëŒ€ìƒì¸ client_id_setë„ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        day_list = []
        client_id_set = set()
        for c in clients:
            (client_id, _, _, _, _, _, _, daily_min, daily_max) = c
            today_count = random.randint(daily_min, daily_max)
            for _ in range(today_count):
                day_list.append(c)
            client_id_set.add(client_id)
        random.shuffle(day_list)
        return day_list, client_id_set

    async def generate_title_keywords(self, keyword: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í˜¸ì¶œ: ì œëª©, LSI í‚¤ì›Œë“œ, ë¡±í…Œì¼ í‚¤ì›Œë“œ ìƒì„±"""
        start_time = time.time()

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ë¨¼ì € ìƒì„±
        keywords_prompt = f"""
ë©”ì¸ í‚¤ì›Œë“œ: {keyword}

ì´ ë©”ì¸ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì•„ë˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:

1) lsi_keywords: ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê´€ëœ LSI í‚¤ì›Œë“œ 5-10ê°œ ë°°ì—´
2) longtail_keywords: êµ¬ì²´ì ì¸ ë¡±í…Œì¼ í‚¤ì›Œë“œ 5-10ê°œ ë°°ì—´

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "lsi_keywords": ["..."],
  "longtail_keywords": ["..."]
}}
"""
        print("   ğŸ“ 1ë‹¨ê³„: LSI/ë¡±í…Œì¼ í‚¤ì›Œë“œ ìƒì„± ì¤‘...")

        # í‚¤ì›Œë“œ ìƒì„± í˜¸ì¶œ
        keywords_response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": keywords_prompt}],
        )

        try:
            import re, json as _json

            response_content = keywords_response.choices[0].message.content
            m = re.search(r"\{[\s\S]*\}$", response_content.strip())
            keywords_data = (
                _json.loads(m.group(0)) if m else _json.loads(response_content)
            )
            lsi_keywords = keywords_data.get("lsi_keywords", [])
            longtail_keywords = keywords_data.get("longtail_keywords", [])
        except Exception:
            lsi_keywords = [f"{keyword} íŒ", f"{keyword} ë°©ë²•"]
            longtail_keywords = [f"{keyword} ì´ˆë³´ ê°€ì´ë“œ"]

        print("   ğŸ“ 2ë‹¨ê³„: ì œëª© ìƒì„± ì¤‘...")

        # 2ë‹¨ê³„: í‚¤ì›Œë“œë“¤ì„ ì¡°í•©í•´ì„œ ì œëª© ìƒì„±
        all_keywords = [keyword] + lsi_keywords[:5] + longtail_keywords[:3]

        title_prompt = f"""
ë©”ì¸ í‚¤ì›Œë“œ: {keyword}
LSI í‚¤ì›Œë“œ: {', '.join(lsi_keywords[:5])}
ë¡±í…Œì¼ í‚¤ì›Œë“œ: {', '.join(longtail_keywords[:3])}

ìœ„ í‚¤ì›Œë“œë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°í•©í•˜ì—¬ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ì œëª©ì„ ë§Œë“œì„¸ìš”.
- ë©”ì¸ í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ í¬í•¨
- LSIë‚˜ ë¡±í…Œì¼ í‚¤ì›Œë“œ 1-2ê°œë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- 60ì ì´ë‚´
- í´ë¦­ì„ ìœ ë„í•˜ëŠ” ë§¤ë ¥ì ì¸ ì œëª©

ì œëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš” (JSONì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ ì—†ì´):
"""

        # ì œëª© ìƒì„±
        title_response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": title_prompt}],
        )
        generated_title = title_response.choices[0].message.content.strip().strip('"')

        print(f"   ğŸ“ ìƒì„±ëœ ì œëª©: {generated_title}")

        # ë¹„ìš© ì¶”ì 
        duration = time.time() - start_time
        prompt_tokens = int(len(keywords_prompt.split()) * 1.3) + int(
            len(title_prompt.split()) * 1.3
        )
        completion_tokens = int(
            len(keywords_response.choices[0].message.content.split()) * 1.3
        ) + int(len(title_response.choices[0].message.content.split()) * 1.3)

        self.track_llm_call(
            "generate_title_keywords",
            prompt_tokens,
            completion_tokens,
            duration,
            f"í‚¤ì›Œë“œ: {len(lsi_keywords + longtail_keywords)}ê°œ, ì œëª©: {generated_title}",
            "í‚¤ì›Œë“œ ë¨¼ì € ìƒì„± â†’ ì œëª© ì¡°í•© ìƒì„±",
        )

        result = {
            "title": generated_title,
            "lsi_keywords": lsi_keywords,
            "longtail_keywords": longtail_keywords,
            "notes": f"ë©”ì¸ í‚¤ì›Œë“œ '{keyword}' ê¸°ë°˜ìœ¼ë¡œ LSI/ë¡±í…Œì¼ í‚¤ì›Œë“œë¥¼ ë¨¼ì € ìƒì„±í•œ í›„ ì œëª©ì„ ì¡°í•© ìƒì„±",
        }

        # ë””ë²„ê¹…ìš© ë°ì´í„° ì €ì¥
        self.save_debug_data(keyword, "title_keywords", result, "json")

        return result

    async def generate_structure_json(
        self, title: str, keyword: str, lsi: List[str], longtail: List[str]
    ) -> Dict[str, Any]:
        """ë¸”ë¡œê·¸ êµ¬ì¡° JSON ìƒì„± (7-10ê°œ H2 ì„¹ì…˜, ê°œìš”+ë§ˆë¬´ë¦¬+FAQ í¬í•¨)"""
        import random

        start_time = time.time()
        target_sections = random.randint(7, 10)
        joined = ", ".join((lsi or [])[:5] + (longtail or [])[:3])
        prompt = f"""
ì œëª©: {title}
í‚¤ì›Œë“œ: {keyword}
ì—°ê´€ í‚¤ì›Œë“œ: {joined}

ì•„ë˜ ì¡°ê±´ìœ¼ë¡œ ë¸”ë¡œê·¸ ë¬¸ì„œ êµ¬ì¡°ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
- H2 ì„¹ì…˜ ìˆ˜: ì •í™•íˆ {target_sections}ê°œ
- ì²« ë²ˆì§¸ H2ëŠ” ë°˜ë“œì‹œ 'ê°œìš”', 'ì†Œê°œ', 'ì‹œì‘í•˜ê¸°' ì¤‘ í•˜ë‚˜ì˜ ì„±ê²©ì„ ê°€ì§„ ë„ì… ì„¹ì…˜ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ììœ ë¡­ê²Œ í‘œí˜„ ê°€ëŠ¥)
- ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ H2ëŠ” 'ì •ë¦¬ì™€ ë§ˆë¬´ë¦¬', 'ìš”ì•½ê³¼ ê²°ë¡ ', 'í•µì‹¬ í¬ì¸íŠ¸' ë“± ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì„¹ì…˜ì´ì–´ì•¼ í•©ë‹ˆë‹¤
- ë§ˆì§€ë§‰ H2ëŠ” ë°˜ë“œì‹œ 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'FAQ', 'ê¶ê¸ˆí•œ ì ë“¤' ë“± ì§ˆë¬¸-ë‹µë³€ í˜•íƒœì˜ ì„¹ì…˜ì´ì–´ì•¼ í•©ë‹ˆë‹¤
- ê° H2ë§ˆë‹¤ H3/H4ëŠ” ìœ ë™ì ìœ¼ë¡œ 0ê°œ ì´ìƒ í¬í•¨ ê°€ëŠ¥
- í•œêµ­ì–´ ì œëª© ì‚¬ìš©, í‚¤ì›Œë“œëŠ” ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨

ë°˜í™˜ í˜•ì‹ ì˜ˆì‹œ:
{{
  "title": "{title}",
  "sections": [
    {{
      "h2": "ì„¹ì…˜ ì œëª©",
      "h3": ["ì†Œì œëª©1", "ì†Œì œëª©2"],
      "h4_map": {{"ì†Œì œëª©1": ["í•­ëª©1", "í•­ëª©2"]}}
    }}
  ]
}}
ë°˜ë“œì‹œ ìœ„ì˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

        response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": prompt}],
        )
        duration = time.time() - start_time
        prompt_tokens = int(len(prompt.split()) * 1.3)
        completion_tokens = int(len(response.choices[0].message.content.split()) * 1.3)

        self.track_llm_call(
            "structure_generation",
            prompt_tokens,
            completion_tokens,
            duration,
            response.choices[0].message.content,
            "7-10ê°œì˜ H2ì™€ ìœ ë™ H3/H4 êµ¬ì¡° JSON (ê°œìš”+ë§ˆë¬´ë¦¬+FAQ í¬í•¨)",
        )

        try:
            import re, json as _json

            response_content = response.choices[0].message.content
            m = re.search(r"\{[\s\S]*\}$", response_content.strip())
            data = _json.loads(m.group(0)) if m else _json.loads(response_content)

            # ë””ë²„ê¹…ìš© ë°ì´í„° ì €ì¥
            self.save_debug_data(keyword, "structure", data, "json")

            return data
        except Exception as e:
            print(f"âŒ êµ¬ì¡° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            fallback_data = {"title": title, "sections": []}
            self.save_debug_data(
                keyword,
                "structure_error",
                {"error": str(e), "fallback": fallback_data},
                "json",
            )
            return fallback_data

    async def generate_section_with_context(
        self,
        idx: int,
        total: int,
        section: Dict[str, Any],
        keyword: str,
        title: str,
        full_structure_json: Dict[str, Any],
        prev_summary: str = "",
        next_h2: str = "",
        lsi_keywords: List[str] = None,
        longtail_keywords: List[str] = None,
    ) -> Tuple[str, List[str]]:
        """ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„± (ì»¨í…ìŠ¤íŠ¸ì™€ í‹°ì € í¬í•¨, ì‚¬ìš©ëœ í‚¤ì›Œë“œ ë°˜í™˜)"""
        start_time = time.time()
        structure_str = json.dumps(full_structure_json, ensure_ascii=False)
        ctx = f"ì´ì „ ì„¹ì…˜ ìš”ì•½: {prev_summary}\n" if prev_summary else ""

        # í‹°ì € ë¬¸ì¥ ê°€ì´ë“œ (ëª…ì‹œì  í‘œí˜„ ê¸ˆì§€)
        teaser = (
            f"ë§ˆì§€ë§‰ ë¬¸ì¥ì€ '{next_h2}'ì™€ ì£¼ì œê°€ ë§ë‹¿ì•„ ìˆìŒì„ ë…ìê°€ ì•”ì‹œì ìœ¼ë¡œ ëŠë¼ë„ë¡, êµ¬ì²´ì  ì •ë³´ í•œ ì¡°ê°ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”. \n- ê¸ˆì§€ í‘œí˜„: 'ë‹¤ìŒ', 'ë‹¤ìŒ ì„¹ì…˜', 'ë‹¤ìŒ ì±•í„°', 'ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§‘ë‹ˆë‹¤'"
            if next_h2
            else ""
        )

        # ê¸¸ì´ ì •ì±…: 1ì„¹ì…˜ 300ì ë‚´ì™¸, ê·¸ ì™¸ 500-800ì
        length_rule = "ë¶„ëŸ‰: ì•½ 300ì" if idx == 1 else "ë¶„ëŸ‰: 500-800ì"

        # LSI/ë¡±í…Œì¼ í‚¤ì›Œë“œë¥¼ ì„¹ì…˜ë³„ë¡œ í™•ë¥ ì ìœ¼ë¡œ 0-1ê°œ ì„ íƒ
        import random

        section_keywords = []

        combined_keywords = []
        if lsi_keywords:
            combined_keywords.extend(lsi_keywords)
        if longtail_keywords:
            combined_keywords.extend(longtail_keywords)

        # ì„¹ì…˜ë‹¹ 50% í™•ë¥ ë¡œ ìµœëŒ€ 1ê°œ í‚¤ì›Œë“œë§Œ ì„ íƒ (ìì—°ìŠ¤ëŸ¬ìš´ í¬í•¨ ìœ ë„)
        if combined_keywords and random.random() < 0.5:
            section_keywords.append(random.choice(combined_keywords))

        # í‚¤ì›Œë“œ ì •ë³´ êµ¬ì„± (ì„ íƒì  ì‚¬ìš©ì„ ê°•ì¡°)
        keywords_info = ""
        if section_keywords:
            keywords_info += (
                "ì„ íƒì  í‚¤ì›Œë“œ ëª©ë¡ (ìì—°ìŠ¤ëŸ¬ìš´ ê²½ìš°ì—ë§Œ ì‚¬ìš©):\n"
                + "\n".join([f"- {kw}" for kw in section_keywords])
                + "\nâ€» ìœ„ í‚¤ì›Œë“œë“¤ì„ ì–µì§€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë§¥ì—ì„œë§Œ ì‚¬ìš©í•˜ê±°ë‚˜, ì–´ìƒ‰í•˜ë‹¤ë©´ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤."
            )

        prompt = f"""
ë¬¸ì„œ ì œëª©: {title}

ì „ì²´ ë¬¸ì„œ êµ¬ì¡°(JSON): {structure_str}
í˜„ì¬ ì„¹ì…˜: {idx}/{total} - H2: {section.get('h2')}
{ctx}
ìš”êµ¬ì‚¬í•­:
1) í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ë³¸ë¬¸
2) H3 ì†Œì œëª© 2-3ê°œ í¬í•¨ ê°€ëŠ¥ (ìˆë‹¤ë©´ Markdown ### ì‚¬ìš©)
3) ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ë‚´ìš©
4) {length_rule}
5) {teaser}
6) ì¶œë ¥ì€ "ë³¸ë¬¸ë§Œ" ì‘ì„±. ì„¹ì…˜ ì œëª©ì´ë‚˜ H2(##)ë¥¼ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ. 'ì„¹ì…˜ ë³¸ë¬¸:' ê°™ì€ ì•ˆë‚´ ë¬¸êµ¬ë„ ê¸ˆì§€.
7) ì²« ì¤„ì— ì„¹ì…˜ ì œëª©ì„ ë°˜ë³µí•˜ì§€ ë§ ê²ƒ. í•„ìš” ì‹œ H3(###)ë¶€í„° ì‹œì‘.
8) í‘œ í˜•íƒœë¡œ í‘œí˜„í•˜ë©´ ë” íš¨ê³¼ì ì¸ ë‚´ìš©ì´ ìˆë‹¤ë©´ Markdown í‘œ ë¬¸ë²• ì‚¬ìš©:
   - ë¹„êµí‘œ: | í•­ëª© | ì„¤ëª… | ë¹„ê³  |
   - ë‹¨ê³„ë³„ í‘œ: | ë‹¨ê³„ | ë‚´ìš© | íŒ |
   - íŠ¹ì§•í‘œ: | íŠ¹ì§• | ì¥ì  | ë‹¨ì  |
   - ì˜ˆì‹œ: | êµ¬ë¶„ | ë°©ë²• | íš¨ê³¼ |
   - ë„êµ¬ ë¹„êµ: | ë„êµ¬ëª… | ì¥ì  | ë‹¨ì  | ê°€ê²© |
   - ë‹¨ê³„ë³„ ê°€ì´ë“œ: | ë‹¨ê³„ | ì„¤ëª… | ì£¼ì˜ì‚¬í•­ |
   - íŒ ì •ë¦¬: | ìƒí™© | í•´ê²°ë°©ë²• | íš¨ê³¼ |
9) {keywords_info}
ë³¸ë¬¸ ì¶œë ¥ ì‹œì‘:
"""

        response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": prompt}],
        )
        duration = time.time() - start_time
        prompt_tokens = int(len(prompt.split()) * 1.3)
        completion_tokens = int(len(response.choices[0].message.content.split()) * 1.3)

        self.track_llm_call(
            f"section_{idx}",
            prompt_tokens,
            completion_tokens,
            duration,
            response.choices[0].message.content,
            f"ì„¹ì…˜ {idx} ë³¸ë¬¸ ìƒì„±",
        )

        return response.choices[0].message.content.strip(), section_keywords

    async def summarize_previous(self, text: str) -> str:
        """ì´ì „ ì„¹ì…˜ ë‚´ìš© ìš”ì•½"""
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ë§Œ 2-3ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ ìš”ì•½:
---
{text}
---
ìš”ì•½:
"""
        response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": prompt}],
        )
        return response.choices[0].message.content.strip()

    def generate_table_of_contents(self, sections_content: List[Dict]) -> str:
        """H2 ê¸°ë°˜ ëª©ì°¨ ìƒì„± (ì•µì»¤ ë§í¬ í¬í•¨, í•µì‹¬ ìš©ì–´ ì •ë¦¬ í¬í•¨)"""
        toc_lines = ["## ëª©ì°¨\n"]

        # ì²« ë²ˆì§¸: í•µì‹¬ ìš©ì–´ ì •ë¦¬
        toc_lines.append("1. [í•µì‹¬ ìš©ì–´ ì •ë¦¬](#í•µì‹¬-ìš©ì–´-ì •ë¦¬)")

        # ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ (ë²ˆí˜¸ +1)
        for i, section in enumerate(sections_content, 2):  # 2ë¶€í„° ì‹œì‘
            h2_title = section.get("h2_title", f"ì„¹ì…˜ {i}")
            # ë§ˆí¬ë‹¤ìš´ ì•µì»¤ ë§í¬ ìƒì„± (í•œê¸€ -> ì˜ì–´, ê³µë°± -> í•˜ì´í”ˆ)
            anchor_id = (
                h2_title.replace(" ", "-")
                .replace(":", "")
                .replace("?", "")
                .replace("!", "")
                .replace(",", "")
                .replace(".", "")
            )
            toc_lines.append(f"{i}. [{h2_title}](#{anchor_id})")

        return "\n".join(toc_lines) + "\n"

    async def extract_and_explain_terms(self, full_content: str, keyword: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ì–´ë ¤ìš´ ìš©ì–´ ì¶”ì¶œ ë° ì„¤ëª… ìƒì„±"""
        start_time = time.time()

        prompt = f"""
ë‹¤ìŒì€ '{keyword}' ì£¼ì œì˜ ë¸”ë¡œê·¸ ì½˜í…ì¸ ì…ë‹ˆë‹¤.
ì´ˆë³´ìë‚˜ ì¤‘ê¸‰ìê°€ ì½ì„ ë•Œ ì´í•´í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆëŠ” ì „ë¬¸ ìš©ì–´ë¥¼ 5-8ê°œ ì„ ë³„í•˜ê³ , ê°ê°ì„ í•œ ì¤„ë¡œ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

=== ë¸”ë¡œê·¸ ì½˜í…ì¸  ===
{full_content[:4000]}  # í† í° ì œí•œì„ ìœ„í•´ ì¼ë¶€ë§Œ ì‚¬ìš©

=== ì‘ì—… ì§€ì‹œ ===
1. ìœ„ ì½˜í…ì¸ ì—ì„œ ì´ˆë³´ìê°€ ëª¨ë¥¼ ë§Œí•œ ì „ë¬¸ ìš©ì–´ë¥¼ ì„ ë³„í•˜ì„¸ìš”
2. ê° ìš©ì–´ë¥¼ í•œ ì¤„(25ì ì´ë‚´)ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”
3. ì¤‘ë³µ ìš©ì–´ë‚˜ ë„ˆë¬´ ì‰¬ìš´ ìš©ì–´ëŠ” ì œì™¸í•˜ì„¸ìš”
4. ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”

=== ì¶œë ¥ í˜•ì‹ (ì˜ˆì‹œ) ===
í¬ë¡¤ë§: ê²€ìƒ‰ì—”ì§„ì´ ì›¹í˜ì´ì§€ë¥¼ ì½ì–´ê°€ëŠ” ê³¼ì •
ë°±ë§í¬: ë‹¤ë¥¸ ì‚¬ì´íŠ¸ì—ì„œ ë‚´ ì‚¬ì´íŠ¸ë¡œ ì—°ê²°ë˜ëŠ” ë§í¬
ë©”íƒ€íƒœê·¸: ê²€ìƒ‰ì—”ì§„ì—ê²Œ í˜ì´ì§€ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ì½”ë“œ
ì¸ë±ì‹±: ê²€ìƒ‰ì—”ì§„ì´ í˜ì´ì§€ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì‘ì—…
ì•µì»¤í…ìŠ¤íŠ¸: ë§í¬ì— í‘œì‹œë˜ëŠ” í´ë¦­ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸

ìœ„ í˜•ì‹ìœ¼ë¡œ ìš©ì–´ì™€ ì„¤ëª…ë§Œ ì¶œë ¥í•˜ì„¸ìš”:
"""

        response = self.llm.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": prompt}],
        )

        # ìš©ì–´ ì„¹ì…˜ í¬ë§·íŒ… (ì•™ì»¤ ID í¬í•¨)
        terms_section = '<h2 id="terms-section"> í•µì‹¬ ìš©ì–´ ì •ë¦¬</h2>\n\n'
        terms_section += "ë³¸ë¬¸ì„ ì½ê¸° ì „ì— ì•Œì•„ë‘ë©´ ì¢‹ì€ ìš©ì–´ë“¤ì…ë‹ˆë‹¤.\n\n"

        # LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ìš©ì–´ ì •ë¦¬ (ê°œì„ ëœ íŒŒì‹±)
        response_text = response.choices[0].message.content.strip()
        lines = response_text.split("\n")
        terms_found = 0

        for line in lines:
            line = line.strip()
            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            if any(
                skip in line.lower()
                for skip in ["ì¶œë ¥ í˜•ì‹", "ì˜ˆì‹œ", "ì‘ì—… ì§€ì‹œ", "ë¸”ë¡œê·¸ ì½˜í…ì¸ ", "==="]
            ):
                continue

            if ":" in line and len(line) > 8:  # ìµœì†Œ ê¸¸ì´ ì²´í¬ ê°•í™”
                try:
                    # ì½œë¡ ìœ¼ë¡œ ë¶„í• 
                    parts = line.split(":", 1)
                    if len(parts) == 2:
                        term = (
                            parts[0]
                            .strip()
                            .replace("**", "")
                            .replace("-", "")
                            .replace("*", "")
                            .strip()
                        )
                        explanation = parts[1].strip()

                        # ìœ íš¨ì„± ê²€ì‚¬
                        if (
                            term
                            and explanation
                            and len(term) > 1
                            and len(explanation) > 5
                            and not term.isdigit()
                        ):  # ìˆ«ìë§Œì¸ ìš©ì–´ ì œì™¸
                            terms_section += f"**{term}**: {explanation}\n\n"
                            terms_found += 1
                except Exception as e:
                    continue

        # ìš©ì–´ê°€ í•˜ë‚˜ë„ ì¶”ì¶œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ê¸°ë³¸ ìš©ì–´ ì¶”ê°€
        if terms_found == 0:
            terms_section += f"**{keyword}**: ì´ ê¸€ì˜ ì£¼ìš” ì£¼ì œì…ë‹ˆë‹¤\n\n"
            terms_section += (
                f"**SEO**: ê²€ìƒ‰ì—”ì§„ ìµœì í™”ë¡œ ì›¹ì‚¬ì´íŠ¸ ë…¸ì¶œì„ ë†’ì´ëŠ” ê¸°ë²•\n\n"
            )
            terms_section += f"**í‚¤ì›Œë“œ**: ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ë‚˜ ë¬¸êµ¬\n\n"

        duration = time.time() - start_time
        self.track_llm_call(
            "extract_terms",
            int(len(prompt.split()) * 1.3),
            int(len(response.choices[0].message.content.split()) * 1.3),
            duration,
            f"ìš©ì–´ {terms_found}ê°œ ì¶”ì¶œ",
            "ì–´ë ¤ìš´ ìš©ì–´ ì¶”ì¶œ ë° ì„¤ëª…",
        )

        return terms_section

    def create_markdown(
        self,
        title: str,
        keyword: str,
        sections_content: List[Dict[str, Any]],
        keywords: Dict[str, List[str]],
        images: Optional[Dict[str, str]] = None,
        table_of_contents: str = "",
        terms_section: str = "",
    ) -> str:
        """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìƒì„± (ëª©ì°¨, ìš©ì–´ ì •ë¦¬, ì´ë¯¸ì§€ í¬í•¨)"""
        md_content = f"# {title}\n\n"
        # 1. ëª©ì°¨ ì¶”ê°€ (ìµœìƒë‹¨)
        if table_of_contents:
            md_content += table_of_contents + "\n"

        # 2. ë©”ì¸ ì´ë¯¸ì§€ ì¶”ê°€ (ëª©ì°¨ ë‹¤ìŒ)
        if images and "main" in images:
            md_content += f'![{title}]({images["main"]})\n\n'

        # 3. ìš©ì–´ ì •ë¦¬ ì¶”ê°€ (ì´ë¯¸ì§€ ë‹¤ìŒ)
        if terms_section:
            md_content += terms_section + "\n"

        # 4. ë³¸ë¬¸ ì„¹ì…˜ë“¤ (ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¡œ ìƒì„±, HTML ë³€í™˜ê¸°ì—ì„œ ID ì¶”ê°€)
        for i, section in enumerate(sections_content):
            # ë§ˆí¬ë‹¤ìš´ H2 í—¤ë”ë¡œ ìƒì„±
            md_content += f'## {section["h2_title"]}\n\n'

            # ì„¹ì…˜ ì´ë¯¸ì§€ ì¶”ê°€ (20% í™•ë¥ ë¡œ)
            section_image_key = f"section_{i+1}"
            if images and section_image_key in images:
                md_content += (
                    f'![{section["h2_title"]}]({images[section_image_key]})\n\n'
                )

            md_content += f"{section['content']}\n\n"

        return md_content

    async def generate_enhanced_content(
        self, client_tuple, keyword: str, pbn_site: Dict[str, Any] = None
    ) -> Optional[Dict[str, Any]]:
        """ê³ ë„í™”ëœ RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            (client_id, client_name, client_site_url, _, _, _, _, _, _) = client_tuple

            print(f"ğŸ“ ì½˜í…ì¸  ìƒì„± ì‹œì‘: {keyword}")
            start_time = time.time()

            # 1. í‚¤ì›Œë“œì™€ ì œëª© ìƒì„±
            print("ğŸ“ ì œëª© ìƒì„± ì¤‘...")
            tk = await self.generate_title_keywords(keyword)
            print(f"âœ… ì œëª© ìƒì„± ì™„ë£Œ: {tk['title']}")

            # 2. êµ¬ì¡° ìƒì„±
            print("ğŸ“‹ ëª©ì°¨ ìƒì„± ì¤‘...")
            structure = await self.generate_structure_json(
                tk["title"],
                keyword,
                tk.get("lsi_keywords", []),
                tk.get("longtail_keywords", []),
            )
            sections = structure.get("sections", [])
            print(f"âœ… êµ¬ì¡° ìƒì„± ì™„ë£Œ: {len(sections)}ê°œ ì„¹ì…˜")

            # 3. ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„±
            print("ğŸ“„ ì„¹ì…˜ ì½˜í…ì¸  ìƒì„± ì¤‘...")
            sections_content = []
            prev_summary = ""
            all_section_keywords = []
            total = len(sections)

            for i, sec in enumerate(sections, 1):
                next_h2 = sections[i]["h2"] if i < total else ""
                raw, section_keywords = await self.generate_section_with_context(
                    idx=i,
                    total=total,
                    section=sec,
                    keyword=keyword,
                    title=tk["title"],
                    full_structure_json=structure,
                    prev_summary=prev_summary,
                    next_h2=next_h2,
                    lsi_keywords=tk.get("lsi_keywords", []),
                    longtail_keywords=tk.get("longtail_keywords", []),
                )

                all_section_keywords.extend(section_keywords)

                # ëª¨ë¸ ì‘ë‹µ í›„ ì •ë¦¬: ì¤‘ë³µ H2/ì•ˆë‚´ë¬¸ ì œê±°
                content = self._sanitize_section_content(sec.get("h2", ""), raw)
                sections_content.append(
                    {
                        "h2_title": sec.get("h2", f"ì„¹ì…˜ {i}"),
                        "content": content,
                        "target_keywords": section_keywords,
                    }
                )

                # ë‹¤ìŒì„ ìœ„í•œ ìš”ì•½ ìƒì„±
                prev_summary = await self.summarize_previous(content)

            # 4. ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
            print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            images = await self.generate_and_save_images(
                title=tk["title"],
                sections=sections,
                keyword=keyword,
                lsi_keywords=tk.get("lsi_keywords", []),
                longtail_keywords=tk.get("longtail_keywords", []),
                pbn_site=pbn_site,  # PBN ì‚¬ì´íŠ¸ ì •ë³´ ì „ë‹¬í•˜ì—¬ ì¦‰ì‹œ ì—…ë¡œë“œ
            )

            print(f"âœ… ì„¹ì…˜ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {len(sections_content)}ê°œ")

            # 4. ëª©ì°¨ ìƒì„±
            print("ëª©ì°¨ ìƒì„± ì¤‘...")
            table_of_contents = self.generate_table_of_contents(sections_content)
            print("âœ… ëª©ì°¨ ìƒì„± ì™„ë£Œ")

            # 5. í•µì‹¬ ìš©ì–´ ì •ë¦¬ ìƒì„±
            print("ğŸ”‘ í‚¤ì›Œë“œ ì •ì˜ ìƒì„± ì¤‘...")
            full_content = "\n".join([sec["content"] for sec in sections_content])
            terms_section = await self.extract_and_explain_terms(full_content, keyword)
            print("âœ… í•µì‹¬ ìš©ì–´ ì •ë¦¬ ìƒì„± ì™„ë£Œ")

            # 6. ë§ˆí¬ë‹¤ìš´ ìƒì„±
            print("ğŸ”— ì „ì²´ ì½˜í…ì¸  ì¡°í•© ì¤‘...")
            md_content = self.create_markdown(
                tk["title"],
                keyword,
                sections_content,
                {
                    "lsi_keywords": tk.get("lsi_keywords", []),
                    "longtail_keywords": tk.get("longtail_keywords", []),
                },
                {},  # ì´ë¯¸ì§€ëŠ” ì¼ë‹¨ ë¹ˆ ë”•ì…”ë„ˆë¦¬
                table_of_contents,
                terms_section,
            )

            # 7. HTML ë³€í™˜
            print("ğŸ”„ HTML ë³€í™˜ ì¤‘...")
            html_content = self.html_converter.convert_markdown_to_html(md_content)
            print("âœ… HTML ë³€í™˜ ì™„ë£Œ")

            # 8. í†µê³„ ê³„ì‚°
            total_word_count = sum(len(sec["content"]) for sec in sections_content)
            seo_score = (
                len(tk.get("lsi_keywords", [])) * 10
                + len(tk.get("longtail_keywords", [])) * 5
                + total_word_count // 10
            )

            # ê²°ê³¼ êµ¬ì„±
            content = {
                "title": tk["title"],
                "content": md_content,
                "html_content": html_content,
                "statistics": {
                    "total_word_count": total_word_count,
                    "total_sections": len(sections_content),
                    "seo_score": seo_score,
                    "content_type": "guide",
                },
                "meta_data": {
                    "target_keyword": keyword,
                    "lsi_keywords": tk.get("lsi_keywords", []),
                    "longtail_keywords": tk.get("longtail_keywords", []),
                },
                "sections": sections_content,
                "images": images,  # ìƒì„±ëœ ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
            }

            # 9. ë””ë²„ê¹…ìš© íŒŒì¼ ì €ì¥
            print("ğŸ’¾ ë””ë²„ê¹… ë°ì´í„° ì €ì¥ ì¤‘...")
            self.save_debug_data(keyword, "final_content", content, "json")
            self.save_debug_data(keyword, "blog", md_content, "md")
            self.save_debug_data(keyword, "blog_html", html_content, "html")

            # 10. ì½˜í…ì¸  í¬ê¸° ê²€ì‚¬
            print("ğŸ“ ì½˜í…ì¸  í¬ê¸° ê²€ì‚¬ ì¤‘...")
            if not self.check_content_size(html_content, max_chars=50000):  # 50KB ì œí•œ
                print("âš ï¸ ì½˜í…ì¸ ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ì¶•ì†Œ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                # ì½˜í…ì¸  ì¶•ì†Œ ë¡œì§ (í•„ìš”ì‹œ)
                content["html_content"] = self._truncate_content(html_content, 50000)
                content["content"] = self._truncate_content(md_content, 50000)
                print("âœ… ì½˜í…ì¸  ì¶•ì†Œ ì™„ë£Œ")

            duration = time.time() - start_time
            print(f"âœ… ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {content['title']}")
            print(f"   ğŸ“Š ë‹¨ì–´ ìˆ˜: {content['statistics']['total_word_count']}")
            print(f"   ğŸ“‹ ì„¹ì…˜ ìˆ˜: {content['statistics']['total_sections']}")
            print(f"   ğŸ¯ SEO ì ìˆ˜: {content['statistics']['seo_score']}")
            print(f"   â±ï¸ ìƒì„± ì‹œê°„: {duration:.1f}ì´ˆ")

            return content

        except Exception as e:
            print(f"âŒ ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback

            traceback.print_exc()
            return None

    async def generate_image(self, prompt: str, purpose: str) -> Optional[str]:
        """ì´ë¯¸ì§€ ìƒì„± (gpt-image-1 ëª¨ë¸ ì‚¬ìš©)

        Args:
            prompt: ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸
            purpose: ì´ë¯¸ì§€ ìš©ë„ (cost trackingìš©)

        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ì˜ base64 ë¬¸ìì—´ ë˜ëŠ” None
        """
        try:
            start_time = time.time()

            # OpenAI Image API í˜¸ì¶œ (gpt-image-1ì€ í•­ìƒ base64ë¡œ ë°˜í™˜)
            response = self.openai_client.images.generate(
                model="gpt-image-1",
                prompt=prompt,
                quality="low",  # ì €í’ˆì§ˆ (ê°€ê²© íš¨ìœ¨ì„±)
                size="1024x1024",  # í‘œì¤€ ì‚¬ì´ì¦ˆ
                n=1,  # 1ê°œ ì´ë¯¸ì§€
            )

            duration = time.time() - start_time

            # ë¹„ìš© ê³„ì‚° (gpt-image-1 low quality 1024x1024: $0.011)
            image_cost = 0.011

            # ì´ë¯¸ì§€ ìƒì„± ì¶”ì 
            self.cost_tracker["total_images"] += 1
            self.cost_tracker["image_details"].append(
                {
                    "purpose": purpose,
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "duration_seconds": duration,
                    "prompt": prompt[:100] + "..." if len(prompt) > 100 else prompt,
                    "cost_usd": image_cost,
                    "model": "gpt-image-1",
                    "quality": "low",
                    "size": "1024x1024",
                }
            )

            # base64 ì´ë¯¸ì§€ ë°ì´í„° ë°˜í™˜ (gpt-image-1ì€ í•­ìƒ b64_json í˜•íƒœ)
            return response.data[0].b64_json

        except Exception as e:
            print(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ({purpose}): {e}")
            return None

    def save_image_from_base64(
        self, b64_data: str, file_path: Path, optimize: bool = True
    ) -> bool:
        """base64 ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥ ë° ìµœì í™”

        Args:
            b64_data: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            optimize: ì´ë¯¸ì§€ ìµœì í™” ì—¬ë¶€

        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # base64 ë””ì½”ë”©í•˜ì—¬ PNG íŒŒì¼ë¡œ ì €ì¥
            image_data = base64.b64decode(b64_data)
            file_path.parent.mkdir(exist_ok=True)

            with open(file_path, "wb") as f:
                f.write(image_data)

            # ì´ë¯¸ì§€ ìµœì í™” (ì˜µì…˜)
            if optimize:
                # ë¸”ë¡œê·¸ìš© ìµœì í™”: 512x512 ì´í•˜, 50KB ì´í•˜ë¡œ ì••ì¶•
                optimization_result = self.image_optimizer.optimize_for_web(
                    file_path,
                    max_size=(512, 512),
                    target_file_size_kb=50,
                    quality_range=(70, 90),
                )

                if optimization_result["success"]:
                    reduction = optimization_result["size_reduction_percent"]
                    print(
                        f"     ğŸ“‰ ì´ë¯¸ì§€ ìµœì í™”: {optimization_result['file_size_change']} ({reduction}% ê°ì†Œ)"
                    )
                else:
                    print(
                        f"     âš ï¸ ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {optimization_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                    )

            return True
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    async def generate_and_save_images(
        self,
        title: str,
        sections: List[Dict],
        keyword: str,
        lsi_keywords: List[str] = None,
        longtail_keywords: List[str] = None,
        pbn_site: Dict[str, Any] = None,
    ) -> Dict[str, str]:
        """ë©”ì¸ ë° ì„¹ì…˜ë³„ ì´ë¯¸ì§€ ìƒì„±, ì €ì¥ ë° ì¦‰ì‹œ ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ

        Args:
            title: ë¸”ë¡œê·¸ ì œëª©
            sections: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
            keyword: ë©”ì¸ í‚¤ì›Œë“œ
            lsi_keywords: LSI í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            longtail_keywords: ë¡±í…Œì¼ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            pbn_site: PBN ì‚¬ì´íŠ¸ ì •ë³´ (ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œìš©)

        Returns:
            ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬ {"main": "url", "section_1": "url", ...}
        """
        images = {}
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_keyword = self._safe_fragment(keyword)
        images_dir = Path("images")
        images_dir.mkdir(parents=True, exist_ok=True)

        # 1. ë©”ì¸ ì´ë¯¸ì§€ ìƒì„± (100% í™•ë¥ )
        print("4. ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        main_prompt = f"Create a professional diagram or infographic about '{title}'. Chart, concept diagram, or infographic style. No text or words in the image. Clean, modern design."

        main_image_data = await self.generate_image(
            main_prompt, f"ë©”ì¸ ì´ë¯¸ì§€: {title}"
        )
        if main_image_data:
            main_image_path = images_dir / f"main_{safe_keyword}_{timestamp}.png"
            if self.save_image_from_base64(
                main_image_data, main_image_path, optimize=True
            ):
                # ì¦‰ì‹œ ì›Œë“œí”„ë ˆìŠ¤ì— ì—…ë¡œë“œ
                if pbn_site:
                    uploaded_url = await self.upload_single_image_to_wordpress(
                        main_image_path, pbn_site, f"ë©”ì¸ ì´ë¯¸ì§€: {title}"
                    )
                    if uploaded_url:
                        images["main"] = uploaded_url
                        print(
                            f"   âœ… ë©”ì¸ ì´ë¯¸ì§€ ìƒì„± ë° ì—…ë¡œë“œ: {main_image_path.name}"
                        )
                    else:
                        images["main"] = str(main_image_path)
                        print(
                            f"   âš ï¸ ë©”ì¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ì—…ë¡œë“œ ì‹¤íŒ¨): {main_image_path.name}"
                        )
                else:
                    images["main"] = str(main_image_path)
                    print(f"   âœ… ë©”ì¸ ì´ë¯¸ì§€ ìƒì„±: {main_image_path.name}")

        # 2. ì„¹ì…˜ë³„ ì´ë¯¸ì§€ ìƒì„± (33% í™•ë¥ )
        for i, section in enumerate(sections):
            if random.random() <= 0.33:  # 33% í™•ë¥ 
                # ì‹¤ì œ ì„¹ì…˜ ì œëª© ì‚¬ìš© (h2 ë˜ëŠ” h2_title)
                section_title = section.get(
                    "h2", section.get("h2_title", f"ì„¹ì…˜ {i+1}")
                )
                section_prompt = f"Create a diagram or concept illustration about '{section_title}'. Professional infographic style. No text or words. Clean design."

                section_image_data = await self.generate_image(
                    section_prompt, f"ì„¹ì…˜ ì´ë¯¸ì§€: {section_title}"
                )
                if section_image_data:
                    section_image_path = (
                        images_dir / f"section_{i+1}_{safe_keyword}_{timestamp}.png"
                    )
                    if self.save_image_from_base64(
                        section_image_data, section_image_path, optimize=True
                    ):
                        # ì¦‰ì‹œ ì›Œë“œí”„ë ˆìŠ¤ì— ì—…ë¡œë“œ
                        if pbn_site:
                            uploaded_url = await self.upload_single_image_to_wordpress(
                                section_image_path,
                                pbn_site,
                                f"ì„¹ì…˜ ì´ë¯¸ì§€: {section_title}",
                            )
                            if uploaded_url:
                                images[f"section_{i+1}"] = uploaded_url
                                print(
                                    f"   âœ… ì„¹ì…˜ {i+1} ì´ë¯¸ì§€ ìƒì„± ë° ì—…ë¡œë“œ: {section_image_path.name}"
                                )
                            else:
                                images[f"section_{i+1}"] = str(section_image_path)
                                print(
                                    f"   âš ï¸ ì„¹ì…˜ {i+1} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ì—…ë¡œë“œ ì‹¤íŒ¨): {section_image_path.name}"
                                )
                        else:
                            images[f"section_{i+1}"] = str(section_image_path)
                            print(
                                f"   âœ… ì„¹ì…˜ {i+1} ì´ë¯¸ì§€ ìƒì„±: {section_image_path.name}"
                            )

        return images

    async def upload_single_image_to_wordpress(
        self, image_path: Path, pbn_site: Dict[str, Any], alt_text: str = ""
    ) -> Optional[str]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ì›Œë“œí”„ë ˆìŠ¤ì— ì—…ë¡œë“œí•˜ê³  URL ë°˜í™˜"""
        try:
            site_url = pbn_site["site_url"]
            username = pbn_site["username"]
            app_password = pbn_site["app_password"]

            print(f"   ğŸ“¤ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘: {image_path.name}")

            # WordPressManagerë¥¼ ì‚¬ìš©í•œ ì—…ë¡œë“œ
            upload_result = self.wp_manager.upload_image_to_wordpress(
                site_url=site_url,
                username=username,
                app_password=app_password,
                image_path=str(image_path),
                image_name=image_path.name,
            )

            if isinstance(upload_result, tuple):
                image_id, image_url = upload_result
            elif isinstance(upload_result, dict):
                image_id = upload_result.get("id")
                image_url = upload_result.get("url")
            else:
                print(
                    f"   âŒ ì—…ë¡œë“œ ê²°ê³¼ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {type(upload_result)}"
                )
                return None

            if image_id and image_url:
                print(f"   âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: {image_url}")
                return image_url
            else:
                print(f"   âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨ (ID: {image_id}, URL: {image_url})")
                return None

        except Exception as e:
            print(f"   âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback

            print(f"   ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None

    async def upload_images_to_wordpress(
        self, images: Dict[str, str], pbn_site: Dict[str, Any]
    ) -> Dict[str, str]:
        """
        ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ WordPressì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            images: ì´ë¯¸ì§€ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬ {"main": "path", "section_1": "path", ...}
            pbn_site: PBN ì‚¬ì´íŠ¸ ì •ë³´

        Returns:
            ì—…ë¡œë“œëœ ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬ {"main": "url", "section_1": "url", ...}
        """
        uploaded_images = {}

        if not images:
            print("   ğŸ“· ì—…ë¡œë“œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return uploaded_images

        site_url = pbn_site.get("site_url", "")
        username = pbn_site.get("username", "")
        app_password = pbn_site.get("app_password", "")

        if not all([site_url, username, app_password]):
            print("   âŒ PBN ì‚¬ì´íŠ¸ ì •ë³´ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
            return uploaded_images

        print(f"   ğŸ“¤ {len(images)}ê°œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œì‘...")

        for image_type, image_path in images.items():
            try:
                print(f"   ğŸ“¤ {image_type} ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘...")

                # ì´ë¯¸ì§€ ê²½ë¡œê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                if not isinstance(image_path, str):
                    print(
                        f"   âŒ {image_type} ì´ë¯¸ì§€ ê²½ë¡œê°€ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(image_path)}"
                    )
                    continue

                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not Path(image_path).exists():
                    print(
                        f"   âŒ {image_type} ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}"
                    )
                    continue

                # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±
                image_name = f"{image_type}_{Path(image_path).stem}.jpg"
                print(f"   ğŸ“ ì—…ë¡œë“œí•  íŒŒì¼ëª…: {image_name}")

                # WordPressì— ì—…ë¡œë“œ
                upload_result = self.wp_manager.upload_image_to_wordpress(
                    site_url=site_url,
                    username=username,
                    app_password=app_password,
                    image_path=image_path,
                    image_name=image_name,
                )

                # ê²°ê³¼ ì²˜ë¦¬ (tuple ë˜ëŠ” dict í˜•íƒœì¼ ìˆ˜ ìˆìŒ)
                if isinstance(upload_result, tuple):
                    image_id, image_url = upload_result
                elif isinstance(upload_result, dict):
                    image_id = upload_result.get("id")
                    image_url = upload_result.get("url")
                else:
                    print(
                        f"   âŒ {image_type} ì—…ë¡œë“œ ê²°ê³¼ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {type(upload_result)}"
                    )
                    continue

                if image_id and image_url:
                    uploaded_images[image_type] = image_url
                    print(f"   âœ… {image_type} ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: {image_url}")
                else:
                    print(
                        f"   âŒ {image_type} ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨ (ID: {image_id}, URL: {image_url})"
                    )

            except Exception as e:
                print(f"   âŒ {image_type} ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback

                print(f"   ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        return uploaded_images

    def insert_images_into_content(
        self, content: str, images: Dict[str, str], sections: List[Dict]
    ) -> str:
        """
        ì½˜í…ì¸ ì— ì´ë¯¸ì§€ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.

        Args:
            content: ì›ë³¸ HTML ì½˜í…ì¸ 
            images: ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬ {"main": "url", "section_1": "url", ...}
            sections: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì´ë¯¸ì§€ê°€ ì‚½ì…ëœ HTML ì½˜í…ì¸ 
        """
        if not images:
            return content

        # ë©”ì¸ ì´ë¯¸ì§€ë¥¼ ëª©ì°¨ ì•„ë˜ì— ì‚½ì…
        if "main" in images:
            main_image_html = f"""<figure class="fs-figure">
<img src="{images['main']}" alt="ë©”ì¸ ì´ë¯¸ì§€" loading="lazy">
</figure>
"""
            # nav íƒœê·¸ ì•„ë˜ì— ì´ë¯¸ì§€ ì‚½ì…
            if "<nav" in content and "</nav>" in content:
                content = re.sub(
                    r"(</nav>\s*)",
                    r"\1" + main_image_html + r"\n",
                    content,
                    flags=re.DOTALL,
                )
            elif "<article" in content:
                # navê°€ ì—†ìœ¼ë©´ article ë°”ë¡œ ì•„ë˜ ì²« ë²ˆì§¸ íƒœê·¸ ìœ„ì— ì‚½ì…
                content = re.sub(
                    r"(<article[^>]*>\s*)(<[^>]+>)",
                    r"\1" + main_image_html + r"\n\2",
                    content,
                    flags=re.DOTALL,
                )
            else:
                # article íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì½˜í…ì¸  ì‹œì‘ ë¶€ë¶„ì— ì‚½ì…
                content = main_image_html + content

        # ì„¹ì…˜ë³„ ì´ë¯¸ì§€ ì‚½ì…
        # ì‹¤ì œ HTMLì—ì„œëŠ” ëª©ì°¨ + í•µì‹¬ìš©ì–´ì •ë¦¬ ì„¹ì…˜ì´ ì¶”ê°€ë˜ë¯€ë¡œ ì¸ë±ìŠ¤ +2 ì¡°ì •
        for i, section in enumerate(sections, 1):
            section_key = f"section_{i}"
            if section_key in images:
                section_title = section.get("h2", f"ì„¹ì…˜ {i}")
                section_image_html = f"""<figure class="fs-figure">
<img src="{images[section_key]}" alt="{section_title} ì´ë¯¸ì§€" loading="lazy">
</figure>
"""

                # H2 íƒœê·¸ë¥¼ ì°¾ì•„ì„œ ì´ë¯¸ì§€ ì‚½ì…
                # 1. ì •í™•í•œ ì œëª©ìœ¼ë¡œ ì°¾ê¸°
                exact_pattern = f"<h2[^>]*>.*?{re.escape(section_title)}.*?</h2>"
                if re.search(exact_pattern, content, flags=re.IGNORECASE | re.DOTALL):
                    content = re.sub(
                        exact_pattern,
                        f"\\g<0>\n\n{section_image_html}",
                        content,
                        flags=re.IGNORECASE | re.DOTALL,
                    )
                    print(f"   âœ… ì„¹ì…˜ {i} ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ: {section_title}")
                    continue

                # 2. ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì°¾ê¸° (ì œëª©ì˜ ì¼ë¶€ë§Œ í¬í•¨)
                partial_patterns = [
                    f"<h2[^>]*>.*?{re.escape(section_title[:10])}.*?</h2>",  # ì• 10ê¸€ì
                    f"<h2[^>]*>.*?{re.escape(section_title[:5])}.*?</h2>",  # ì• 5ê¸€ì
                ]

                for pattern in partial_patterns:
                    if re.search(pattern, content, flags=re.IGNORECASE | re.DOTALL):
                        content = re.sub(
                            pattern,
                            f"\\g<0>\n\n{section_image_html}",
                            content,
                            flags=re.IGNORECASE | re.DOTALL,
                        )
                        print(
                            f"   âœ… ì„¹ì…˜ {i} ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ (ë¶€ë¶„ë§¤ì¹­): {section_title}"
                        )
                        break
                else:
                    # 3. ì„¹ì…˜ ì¸ë±ìŠ¤ë¡œ ì°¾ê¸° (section íƒœê·¸ ë‚´ì˜ H2)
                    section_pattern = f"<section[^>]*>.*?<h2[^>]*>.*?</h2>"
                    section_matches = list(
                        re.finditer(
                            section_pattern, content, flags=re.IGNORECASE | re.DOTALL
                        )
                    )

                    # ì‹¤ì œ HTMLì—ì„œëŠ” í•µì‹¬ìš©ì–´ì •ë¦¬ ì„¹ì…˜ì´ ì¶”ê°€ë˜ë¯€ë¡œ ì¸ë±ìŠ¤ ì¡°ì •
                    # JSON ì„¹ì…˜ i â†’ HTML ì„¹ì…˜ i (í•µì‹¬ìš©ì–´ì •ë¦¬ê°€ 0ë²ˆ, JSON ì„¹ì…˜ 1ì´ HTML ì„¹ì…˜ 1)
                    adjusted_index = i  # iëŠ” 1ë¶€í„° ì‹œì‘, ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    print(
                        f"   ğŸ” ì„¹ì…˜ {i} ë””ë²„ê¹…: JSON ì„¹ì…˜ {i} â†’ HTML ì„¹ì…˜ {adjusted_index} (ì´ {len(section_matches)}ê°œ ì„¹ì…˜)"
                    )
                    # ì‹¤ì œ ì„¹ì…˜ ì œëª©ë“¤ ì¶œë ¥
                    for idx, match in enumerate(section_matches[:5]):  # ì²˜ìŒ 5ê°œë§Œ
                        section_text = (
                            match.group(0)[:100] + "..."
                            if len(match.group(0)) > 100
                            else match.group(0)
                        )
                        print(f"     HTML ì„¹ì…˜ {idx}: {section_text}")
                    if adjusted_index < len(section_matches):
                        section_match = section_matches[adjusted_index]
                        section_start = section_match.start()
                        section_end = section_match.end()

                        # í•´ë‹¹ ì„¹ì…˜ì˜ H2 íƒœê·¸ ì°¾ê¸°
                        h2_in_section = re.search(
                            r"<h2[^>]*>.*?</h2>",
                            content[section_start:section_end],
                            flags=re.IGNORECASE | re.DOTALL,
                        )
                        if h2_in_section:
                            h2_start = section_start + h2_in_section.start()
                            h2_end = section_start + h2_in_section.end()

                            # H2 íƒœê·¸ ë’¤ì— ì´ë¯¸ì§€ ì‚½ì…
                            content = (
                                content[:h2_end]
                                + "\n\n"
                                + section_image_html
                                + content[h2_end:]
                            )
                            print(
                                f"   âœ… ì„¹ì…˜ {i} ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ (ì¸ë±ìŠ¤ë§¤ì¹­): {section_title}"
                            )
                            continue

                    # 4. ë””ë²„ê¹…ì„ ìœ„í•´ ì‹¤ì œ H2 íƒœê·¸ë“¤ ì¶œë ¥
                    h2_matches = re.findall(
                        r"<h2[^>]*>(.*?)</h2>", content, flags=re.IGNORECASE | re.DOTALL
                    )
                    print(f"   âš ï¸ ì„¹ì…˜ {i} H2 íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {section_title}")
                    print(f"   ğŸ“‹ ì‹¤ì œ H2 íƒœê·¸ë“¤: {h2_matches[:5]}")  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥

        return content

    def _sanitize_section_content(self, h2_title: str, content: str) -> str:
        """ëª¨ë¸ ì‘ë‹µì—ì„œ ì¤‘ë³µ H2/ì•ˆë‚´ë¬¸ ë“±ì„ ì œê±°í•˜ì—¬ ê¹”ë”í•œ ë³¸ë¬¸ë§Œ ë‚¨ê¸´ë‹¤."""
        import re

        lines = [ln.rstrip() for ln in content.strip().split("\n")]
        sanitized: list[str] = []
        skip_prefixes = {
            "ì„¹ì…˜ ë³¸ë¬¸:",
            "ë³¸ë¬¸:",
            "ë³¸ë¬¸ ì¶œë ¥:",
            "ë³¸ë¬¸ ì¶œë ¥ ì‹œì‘:",
            "ë‚´ìš©:",
        }

        for i, ln in enumerate(lines):
            # ì²« ë¶€ë¶„ì—ì„œë§Œ ê°•ì œ ì œê±° ê·œì¹™ ì ìš©
            if i < 5:
                # 'ì„¹ì…˜ ë³¸ë¬¸:' ë¥˜ ì•ˆë‚´ë¬¸ ì œê±°
                if any(ln.strip().startswith(p) for p in skip_prefixes):
                    continue
                # ì¤‘ë³µ H2 ì œê±° (## ...)
                if ln.strip().startswith("## "):
                    continue
                # ì„¹ì…˜ ì œëª© ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±° (ì œëª©ë§Œ ë‹¨ë… ë¼ì¸)
                if ln.strip() == h2_title.strip():
                    continue
            sanitized.append(ln)

        # ì•ë’¤ ê³µë°± ì •ë¦¬ ë° ì—°ì† ë¹ˆ ì¤„ ì¶•ì†Œ
        out = "\n".join(sanitized).strip()
        out = re.sub(r"\n\s*\n\s*\n+", "\n\n", out)
        return out

    def _convert_content_to_html(self, content: Dict[str, Any]) -> str:
        """ì½˜í…ì¸ ë¥¼ HTMLë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            html_content = self.html_converter.convert_markdown_to_html(
                content["content"]
            )
            html_with_meta = self._add_html_metadata(html_content, content)
            return html_with_meta
        except Exception as e:
            print(f"âŒ HTML ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return content["content"]

    def _add_html_metadata(self, html_content: str, content: Dict[str, Any]) -> str:
        """HTML ì½˜í…ì¸ ì— ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        try:
            stats = content["statistics"]
            meta_comment = f"""<!-- 
ì½˜í…ì¸  ìƒì„± ì •ë³´:
- ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- íƒ€ê²Ÿ í‚¤ì›Œë“œ: {content['meta_data']['target_keyword']}
- ë‹¨ì–´ ìˆ˜: {stats['total_word_count']}
- ì„¹ì…˜ ìˆ˜: {stats['total_sections']}
- SEO ì ìˆ˜: {stats['seo_score']}
- ì½˜í…ì¸  ìœ í˜•: {stats['content_type']}
-->"""

            return meta_comment + "\n" + html_content
        except Exception as e:
            print(f"âŒ HTML ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return html_content

    async def process_client(self, client_tuple, pbn_sites, test_keyword=None):
        """
        í•œ í´ë¼ì´ì–¸íŠ¸ì— ëŒ€í•´ ì „ì²´ í¬ìŠ¤íŒ… ì‘ì—…(í‚¤ì›Œë“œ ì„ ì •, ì½˜í…ì¸  ìƒì„±,
        ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ, DB ê¸°ë¡)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            client_tuple: í´ë¼ì´ì–¸íŠ¸ ì •ë³´ íŠœí”Œ
            pbn_sites: PBN ì‚¬ì´íŠ¸ ëª©ë¡
            test_keyword: í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œ (ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹œ ì‚¬ìš©)
        """
        try:
            (client_id, client_name, client_site_url, _, _, _, _, _, _) = client_tuple

            # í‚¤ì›Œë“œ ì„ ì • (í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ DBì—ì„œ ëœë¤ ì„ íƒ)
            if test_keyword:
                keyword = test_keyword
                print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œ ì‚¬ìš©: {keyword}")
            else:
                keyword = get_random_keyword_for_client(client_id)
                if not keyword:
                    print(f"í´ë¼ì´ì–¸íŠ¸ {client_id}ì— í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    return False

            # PBN ì‚¬ì´íŠ¸ ëœë¤ ì„ íƒ
            pbn_site_tuple = random.choice(pbn_sites)
            pbn_site_id, pbn_url, pbn_user, pbn_pass, pbn_app_pass = pbn_site_tuple

            # PBN ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            pbn_site = {
                "site_id": pbn_site_id,
                "site_url": pbn_url,
                "username": pbn_user,
                "password": pbn_pass,
                "app_password": pbn_app_pass,
            }

            print(f"ğŸŒ PBN ì‚¬ì´íŠ¸ ì²˜ë¦¬ ì¤‘: {pbn_url}")

            # ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± (ë¹„ë™ê¸°)
            content = await self.generate_enhanced_content(
                client_tuple, keyword, pbn_site
            )
            if not content:
                print(f"âŒ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {keyword}")
                return False

            # ì›ë³¸ HTML ì½˜í…ì¸  ì‚¬ìš© (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼)
            if "html_content" in content and content["html_content"]:
                print("ğŸ“„ ì›ë³¸ HTML ì½˜í…ì¸  ì‚¬ìš© ì¤‘...")
                post_content = content["html_content"]
                self.save_debug_data(keyword, "original_html", post_content, "html")
                print(
                    f"âœ… ì›ë³¸ HTML ì½˜í…ì¸  ì‚¬ìš© ì™„ë£Œ (í¬ê¸°: {len(post_content)} ë°”ì´íŠ¸)"
                )
            else:
                # ëŒ€ì²´ ë°©ì•ˆ: ê°„ë‹¨í•œ HTML ì½˜í…ì¸  ìƒì„±
                try:
                    print("ğŸ“„ ê°„ë‹¨í•œ HTML ì½˜í…ì¸  ìƒì„± ì¤‘...")
                    post_content = self._create_simple_html_content(content)
                    self.save_debug_data(keyword, "simple_html", post_content, "html")
                    print(
                        f"âœ… ê°„ë‹¨í•œ HTML ì½˜í…ì¸  ìƒì„± ì™„ë£Œ (í¬ê¸°: {len(post_content)} ë°”ì´íŠ¸)"
                    )
                except Exception as e:
                    print(f"âŒ ê°„ë‹¨í•œ HTML ìƒì„± ì‹¤íŒ¨: {e}")
                    # ìµœì¢… ëŒ€ì²´ ë°©ì•ˆ: ê¸°ë³¸ ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸  ì‚¬ìš©
                    try:
                        print("ğŸ“„ ê¸°ë³¸ ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸  ì‚¬ìš© ì¤‘...")
                        post_content = content["content"].replace("\n", "<br>\n")
                        print(
                            f"âœ… ê¸°ë³¸ ì½˜í…ì¸  ì‚¬ìš© ì™„ë£Œ (í¬ê¸°: {len(post_content)} ë°”ì´íŠ¸)"
                        )
                    except Exception as e2:
                        print(f"âŒ ê¸°ë³¸ ì½˜í…ì¸  ì‚¬ìš©ë„ ì‹¤íŒ¨: {e2}")
                        return False

            # ìƒˆë¡œìš´ ì§€ëŠ¥í˜• ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ ì ìš©
            print("ğŸ”— ì§€ëŠ¥í˜• ë§í¬ ë¹Œë”© ì‹œì‘...")
            try:
                # ì½˜í…ì¸ ì—ì„œ í‚¤ì›Œë“œ ì •ë³´ ì¶”ì¶œ
                lsi_keywords = content.get("meta_data", {}).get("lsi_keywords", [])
                longtail_keywords = content.get("meta_data", {}).get(
                    "longtail_keywords", []
                )

                # ì¢…í•©ì ì¸ ë§í¬ ë¹Œë”© ìˆ˜í–‰
                link_result = self.link_builder.build_comprehensive_links(
                    post_content,
                    keyword,
                    client_site_url,
                    lsi_keywords,
                    longtail_keywords,
                )

                # ë§í¬ê°€ ì‚½ì…ëœ ì½˜í…ì¸  ì‚¬ìš©
                post_content = link_result["content"]
                link_report = link_result["report"]

                # ë§í¬ ë¹Œë”© ê²°ê³¼ ì €ì¥
                self.save_debug_data(keyword, "link_report", link_report, "json")

                print(f"âœ… ë§í¬ ë¹Œë”© ì™„ë£Œ: ì´ {link_report['total_links']}ê°œ ë§í¬ ì‚½ì…")
                print(
                    f"   ğŸ¯ í´ë¼ì´ì–¸íŠ¸ ë§í¬: {1 if link_report['client_link'] else 0}ê°œ"
                )
                print(f"   ğŸ”— ë‚´ë¶€ë§í¬: {len(link_report['internal_links'])}ê°œ")
                print(f"   ğŸŒ ì™¸ë¶€ë§í¬: {len(link_report['external_links'])}ê°œ")

            except Exception as e:
                print(f"âš ï¸ ë§í¬ ë¹Œë”© ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                print("   â†’ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ë§í¬ë§Œ ì‚½ì…í•©ë‹ˆë‹¤.")
                # ë°±ì—…: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ë§í¬ë§Œ ì‚½ì…
                post_content = insert_anchor_text(
                    post_content, keyword, client_site_url
                )

            # ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì‚½ì… (ì´ë¯¸ì§€ê°€ ìƒì„±ëœ ê²½ìš°)
            if "images" in content and content["images"]:
                print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚½ì… ì¤‘...")
                try:
                    images_data = content["images"]
                    if isinstance(images_data, dict) and images_data:
                        # ì´ë¯¸ ì—…ë¡œë“œëœ URLì´ë¯€ë¡œ ë°”ë¡œ ì‚½ì…
                        post_content = self.insert_images_into_content(
                            post_content, images_data, content.get("sections", [])
                        )
                        print(f"âœ… {len(images_data)}ê°œ ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ")
                    else:
                        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ì‚½ì… ì¤‘ ì˜¤ë¥˜: {e} - ì´ë¯¸ì§€ ì—†ì´ ì§„í–‰")

            # ì›Œë“œí”„ë ˆìŠ¤ìš© ì½˜í…ì¸  ì •ë¦¬ (ë¹„í™œì„±í™” - êµ¬ì¡° ìœ ì§€)
            # print("ğŸ”§ ì›Œë“œí”„ë ˆìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•œ ì½˜í…ì¸  ì •ë¦¬...")
            # post_content = self._clean_content_for_wordpress(post_content)
            self.save_debug_data(keyword, "original_html", post_content, "html")

            # ìµœì¢… ì—…ë¡œë“œìš© ì½˜í…ì¸  í¬ê¸° ì¬ê²€ì‚¬
            print("ğŸ” ìµœì¢… ì—…ë¡œë“œ ì „ ì½˜í…ì¸  ê²€ì‚¬...")
            if not self.check_content_size(
                post_content, max_chars=30000
            ):  # ë” ë³´ìˆ˜ì ì¸ ì œí•œ
                print("âš ï¸ ì—…ë¡œë“œìš© ì½˜í…ì¸ ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ì¶•ì†Œí•©ë‹ˆë‹¤.")
                post_content = self._truncate_content(post_content, 30000)
                self.save_debug_data(keyword, "truncated_content", post_content, "html")

            # ì›Œë“œí”„ë ˆìŠ¤ REST API ì—°ê²° í…ŒìŠ¤íŠ¸
            print("ğŸ”— ì›Œë“œí”„ë ˆìŠ¤ REST API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
            try:
                wp_api_url = f"{pbn_url.rstrip('/')}/wp-json/wp/v2"
                print(f"   ğŸ“¡ REST API URL: {wp_api_url}")

                # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì¸ì¦ í—¤ë”ë¡œ ì‚¬ìš©ì ì •ë³´ í™•ì¸)
                import requests

                credentials = f"{pbn_user}:{pbn_app_pass}"
                token = base64.b64encode(credentials.encode())
                headers = {
                    "Authorization": f"Basic {token.decode('utf-8')}",
                    "Content-Type": "application/json",
                }

                # ì‚¬ìš©ì ì •ë³´ í™•ì¸ìœ¼ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ 1ë¶„)
                response = requests.get(
                    f"{wp_api_url}/users/me", headers=headers, timeout=60
                )
                if response.status_code == 200:
                    user_info = response.json()
                    print(
                        f"   âœ… REST API ì—°ê²° ì„±ê³µ - ì‚¬ìš©ì: {user_info.get('name', 'N/A')}"
                    )
                else:
                    print(f"   âš ï¸ REST API ì—°ê²° í™•ì¸ ë¶ˆê°€ - HTTP {response.status_code}")
                    # ì—°ê²° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ)
            except Exception as e:
                print(f"   âš ï¸ REST API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                print("   â†’ í¬ìŠ¤íŒ…ì€ ê³„ì† ì‹œë„í•©ë‹ˆë‹¤.")

            # ì›Œë“œí”„ë ˆìŠ¤ì— í¬ìŠ¤íŒ… (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            print("ğŸ“¤ ì›Œë“œí”„ë ˆìŠ¤ì— í¬ìŠ¤íŒ… ì‹œë„ ì¤‘...")

            # í˜„ì¬ PBN ì‚¬ì´íŠ¸ì—ì„œ ì‹œë„, ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ëœë¤ PBNì—ì„œ 1ë²ˆ ì¬ì‹œë„
            success = self._try_posting_with_retry(
                content,
                post_content,
                keyword,
                client_id,
                client_name,
                client_site_url,
                current_pbn_site=(
                    pbn_site_id,
                    pbn_url,
                    pbn_user,
                    pbn_pass,
                    pbn_app_pass,
                ),
            )

            if success:
                return True
            else:
                print(f"âŒ PBN ì¬ì‹œë„ í¬ìŠ¤íŒ… ì‹¤íŒ¨")
                # ì‹¤íŒ¨í•œ ì½˜í…ì¸ ë„ ë””ë²„ê¹…ìš©ìœ¼ë¡œ ì €ì¥
                self.save_debug_data(
                    keyword,
                    "failed_content",
                    {
                        "title": content["title"],
                        "content": post_content,
                        "error": "PBN ì¬ì‹œë„ í¬ìŠ¤íŒ… ì‹¤íŒ¨ (ìµœëŒ€ 2ë²ˆ ì‹œë„)",
                    },
                    "json",
                )
                return False

        except Exception as e:
            print(f"[ERROR] {client_name} / {pbn_url} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            print("â†’ ì´ë²ˆ í¬ìŠ¤íŒ… ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.\n")
            return False

    def update_client_status(self, client_id_set):
        """ì‘ì—… í›„ ê° í´ë¼ì´ì–¸íŠ¸ì˜ remaining_daysë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        for c_id in client_id_set:
            info = view_client_status(c_id)
            if info is None:
                continue
            built_count = info["built_count"]
            total_backlinks = info["remaining_count"] + built_count
            if built_count >= total_backlinks or info["remaining_days"] - 1 <= 0:
                move_client_to_completed(c_id)
                print(f"í´ë¼ì´ì–¸íŠ¸ {c_id} ì‘ì—… ì™„ë£Œ (ë°±ë§í¬ ëª©í‘œ ë‹¬ì„± ë˜ëŠ” ê¸°ê°„ ë§Œë£Œ).")
            else:
                update_client_info(c_id, remaining_days=info["remaining_days"] - 1)

    async def run_automated_campaign(self):
        """ìë™í™”ëœ ë°±ë§í¬ ìº í˜ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("ğŸš€ ìë™í™”ëœ ë°±ë§í¬ ìº í˜ì¸ ì‹œì‘")
        print("=" * 50)

        # 1. í™œì„± í´ë¼ì´ì–¸íŠ¸ ì¡°íšŒ ë° ë¡œê·¸ ì¶œë ¥
        active_clients = self.load_active_clients_and_log()
        if not active_clients:
            return

        # 2. ì˜¤ëŠ˜ ì‘ì—… ëŒ€ìƒ day_listì™€ ì—…ë°ì´íŠ¸í•  client_id_set êµ¬ì„±
        day_list, client_id_set = self.prepare_day_list(active_clients)

        # PBN ì‚¬ì´íŠ¸ ëª©ë¡ ì¡°íšŒ
        pbn_sites = get_all_pbn_sites()
        if not pbn_sites:
            print("PBN ì‚¬ì´íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ“Š ì´ {len(pbn_sites)}ê°œì˜ PBN ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        print(f"ğŸ‘¥ ì´ {len(active_clients)}ëª…ì˜ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ ì˜¤ëŠ˜ ì²˜ë¦¬í•  ì´ ì‘ì—… ìˆ˜: {len(day_list)}")

        # 3. ê° í´ë¼ì´ì–¸íŠ¸ì— ëŒ€í•´ í¬ìŠ¤íŒ… ì‘ì—… ìˆ˜í–‰
        successful_posts = 0
        for idx, client_tuple in enumerate(day_list, start=1):
            success = await self.process_client(
                client_tuple, pbn_sites, test_keyword=None
            )
            result_text = "ì„±ê³µ" if success else "ì‹¤íŒ¨"
            print(f"[{idx}/{len(day_list)}] ì²˜ë¦¬ ê²°ê³¼: {result_text}")
            if success:
                successful_posts += 1

        # 4. ì‘ì—… í›„ í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.update_client_status(client_id_set)

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print("ğŸ‰ ìë™í™”ëœ ë°±ë§í¬ ìº í˜ì¸ ì™„ë£Œ")
        print(f"ğŸ“Š ì´ í¬ìŠ¤íŠ¸ ìˆ˜: {len(day_list)}")
        print(f"âœ… ì„±ê³µí•œ í¬ìŠ¤íŠ¸: {successful_posts}")
        print(f"âŒ ì‹¤íŒ¨í•œ í¬ìŠ¤íŠ¸: {len(day_list) - successful_posts}")
        print(
            f"ğŸ“ˆ ì„±ê³µë¥ : {(successful_posts/len(day_list)*100):.1f}%"
            if len(day_list) > 0
            else "0%"
        )
        print("ì˜¤ëŠ˜ ì‘ì—…ì„ ëª¨ë‘ ë§ˆì³¤ìŠµë‹ˆë‹¤.")

    # ========== ê´€ë¦¬ì ë©”ë‰´ ê¸°ëŠ¥ë“¤ ==========

    def display_menu(self):
        print("\n========== ê³ ë„í™”ëœ PBN ë°±ë§í¬ ìë™í™” ì‹œìŠ¤í…œ ==========")
        print("1. ìë™í™”ëœ ë°±ë§í¬ ìº í˜ì¸ ì‹¤í–‰")
        print("2. PBN ì‚¬ì´íŠ¸ ì¶”ê°€")
        print("3. PBN ì‚¬ì´íŠ¸ ì¡°íšŒ")
        print("4. PBN ì‚¬ì´íŠ¸ ì‚­ì œ")
        print("5. í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€")
        print("6. í´ë¼ì´ì–¸íŠ¸ ì¡°íšŒ")
        print("7. í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ìˆ˜ì •")
        print("8. í´ë¼ì´ì–¸íŠ¸ ë‚¨ì€ ê¸°ê°„ ë‹¨ì¶•/ì—°ì¥")
        print("9. í´ë¼ì´ì–¸íŠ¸ ì‘ì—… ì™„ë£Œ ì²˜ë¦¬")
        print("10. ì™„ë£Œëœ í´ë¼ì´ì–¸íŠ¸ ì¡°íšŒ")
        print("11. ëª¨ë“  í…Œì´ë¸” ìƒíƒœ í™•ì¸")
        print("12. íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ì¡°íšŒ")
        print("13. íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ ì¼ì‹œì •ì§€/ì¬ê°œ")
        print("14. ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì¼ì‹œì •ì§€")
        print("15. ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì¬ê°œ")
        print("16. ë°±ë§í¬ ë³´ê³ ì„œ ì—‘ì…€ë¡œ ì €ì¥")
        print("17. íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ í‚¤ì›Œë“œ ì¡°íšŒ")
        print("18. ì¤‘ë³µ í´ë¼ì´ì–¸íŠ¸ ì œê±°")
        print("19. í™œì„± í´ë¼ì´ì–¸íŠ¸ ëª©ë¡ ì¡°íšŒ")
        print("20. í¬ìŠ¤íŠ¸ ê¸°ë¡ ì¡°íšŒ")
        print("21. ğŸ”— PBN ì½˜í…ì¸  í¬ë¡¤ë§ (ë§í¬ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•)")
        print("22. ğŸ“Š PBN ì½˜í…ì¸  ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ")
        print("23. ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ í¬ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        print("24. ğŸ§ª ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‚¬ì´íŠ¸+í‚¤ì›Œë“œ ì§€ì •)")
        print("q. ì¢…ë£Œ")
        print("==================================================")

    def add_pbn_site_prompt(self):
        site_url = input("PBN ì‚¬ì´íŠ¸ URL ì…ë ¥: ")
        username = input("PBN ì‚¬ì´íŠ¸ ê´€ë¦¬ì ì•„ì´ë”” ì…ë ¥: ")
        password = input("PBN ì‚¬ì´íŠ¸ ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ ì…ë ¥: ")
        app_password = input("PBN ì‚¬ì´íŠ¸ ì‘ìš©í”„ë¡œê·¸ë¨ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥: ")
        add_pbn_site(site_url, username, password, app_password)
        print("PBN ì‚¬ì´íŠ¸ ì¶”ê°€ ì™„ë£Œ")

    def delete_pbn_site_prompt(self):
        view_pbn_sites()
        site_id = int(input("ì‚­ì œí•  PBN site_id ì…ë ¥: "))
        delete_record_by_id("pbn_sites", site_id, "site_id")

    def add_client_prompt(self):
        client_name = input("í´ë¼ì´ì–¸íŠ¸ ì´ë¦„: ").strip()
        site_url = input("í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ ì£¼ì†Œ: ").strip()
        total_backlinks = int(
            input_with_validation(
                "ì´ ë°±ë§í¬ ìˆ˜: ", is_positive_int, "ì–‘ì˜ ì •ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
            )
        )
        remaining_days = int(
            input_with_validation(
                "ì—…ë¡œë“œ ê¸°ê°„(ì¼): ", is_positive_int, "ì–‘ì˜ ì •ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
            )
        )
        daily_min = int(
            input_with_validation(
                "ì¼ì¼ ìµœì†Œ ë°±ë§í¬ ìˆ˜(daily_min): ",
                is_positive_int,
                "ì–‘ì˜ ì •ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
            )
        )
        daily_max = int(
            input_with_validation(
                "ì¼ì¼ ìµœëŒ€ ë°±ë§í¬ ìˆ˜(daily_max): ",
                is_positive_int,
                "ì–‘ì˜ ì •ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
            )
        )
        if daily_min > daily_max:
            print("ì¼ì¼ ìµœì†Œìˆ˜ëŸ‰ì´ ìµœëŒ€ìˆ˜ëŸ‰ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.")
            return

        client_id = add_client(
            client_name, site_url, total_backlinks, remaining_days, daily_min, daily_max
        )
        print(f"í´ë¼ì´ì–¸íŠ¸ '{client_name}' ì¶”ê°€ ì™„ë£Œ. (ID: {client_id})")

        # í‚¤ì›Œë“œ ì…ë ¥ ë¶€ë¶„
        keyword_str = input("ì¶”ê°€í•  í‚¤ì›Œë“œë“¤(ì‰¼í‘œë¡œ êµ¬ë¶„): ").strip()
        if keyword_str:
            for kw in keyword_str.split(","):
                add_client_keyword(client_id, kw.strip())
        print("í‚¤ì›Œë“œ ì¶”ê°€ ì™„ë£Œ.")

    def update_client_prompt(self):
        view_clients()
        client_id = int(input("ìˆ˜ì •í•  í´ë¼ì´ì–¸íŠ¸ ID: "))
        print("\nìˆ˜ì •í•  ë‚´ìš©ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. í´ë¼ì´ì–¸íŠ¸ ì´ë¦„")
        print("2. ì‚¬ì´íŠ¸ ì£¼ì†Œ")
        print("3. í‚¤ì›Œë“œ ì…ë ¥")
        print("4. ë°±ë§í¬ ìˆ˜ëŸ‰(total_backlinks)")
        print("5. ë‚¨ì€ ê¸°ê°„(ë‹¨ì¶•/ì—°ì¥)")
        print("6. ì¼ì¼ ìµœì†Œ/ìµœëŒ€ ë°±ë§í¬ ê°’(daily_min, daily_max) ìˆ˜ì •")
        choice = input("ì„ íƒ: ").strip()

        if choice == "1":
            new_value = input("ìƒˆ í´ë¼ì´ì–¸íŠ¸ ì´ë¦„: ").strip()
            update_client_info(client_id, client_name=new_value)
        elif choice == "2":
            new_value = input("ìƒˆ ì‚¬ì´íŠ¸ ì£¼ì†Œ: ").strip()
            update_client_info(client_id, site_url=new_value)
        elif choice == "3":
            new_keywords = input("ì¶”ê°€í•  í‚¤ì›Œë“œ(ì‰¼í‘œ êµ¬ë¶„): ").strip()
            if new_keywords:
                for kw in new_keywords.split(","):
                    add_client_keyword(client_id, kw.strip())
            print("í‚¤ì›Œë“œ ì¶”ê°€ ì™„ë£Œ.")
        elif choice == "4":
            new_total = int(
                input_with_validation("ìƒˆ ë°±ë§í¬ ìˆ˜(ì–‘ì˜ ì •ìˆ˜): ", is_positive_int)
            )
            update_client_info(client_id, total_backlinks=new_total)
        elif choice == "5":
            new_days = int(input_with_validation("ìƒˆ ë‚¨ì€ ê¸°ê°„(ì¼): ", is_positive_int))
            update_client_info(client_id, remaining_days=new_days)
        elif choice == "6":
            new_min = int(
                input_with_validation("ìƒˆ ì¼ì¼ ìµœì†Œ ë°±ë§í¬ ìˆ˜: ", is_positive_int)
            )
            new_max = int(
                input_with_validation("ìƒˆ ì¼ì¼ ìµœëŒ€ ë°±ë§í¬ ìˆ˜: ", is_positive_int)
            )
            if new_min > new_max:
                print("ìµœì†Œìˆ˜ëŸ‰ì´ ìµœëŒ€ìˆ˜ëŸ‰ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì·¨ì†Œí•©ë‹ˆë‹¤.")
                return
            update_client_info(client_id, daily_min=new_min, daily_max=new_max)
            print("daily_min, daily_max ìˆ˜ì • ì™„ë£Œ.")
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

        print("í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ìˆ˜ì • ì™„ë£Œ")

    def extend_or_reduce_days_prompt(self):
        view_clients()
        client_id = int(input("ê¸°ê°„ ë³€ê²½í•  í´ë¼ì´ì–¸íŠ¸ ID: "))
        change_days = int(input("ë³€ê²½í•  ì¼ìˆ˜(+ëŠ” ì—°ì¥, -ëŠ” ë‹¨ì¶•): "))
        status = view_client_status(client_id)
        if not status:
            print("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.")
            return
        new_days = status["remaining_days"] + change_days
        if new_days < 1:
            print("ë‚¨ì€ ê¸°ê°„ì€ 1ì¼ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return
        update_client_info(client_id, remaining_days=new_days)
        print(f"í´ë¼ì´ì–¸íŠ¸ {client_id}ì˜ ë‚¨ì€ ê¸°ê°„ ë³€ê²½ ì™„ë£Œ: {new_days}ì¼")

    def complete_client_prompt(self):
        view_clients()
        client_id = int(input("ì‘ì—… ì™„ë£Œ ì²˜ë¦¬í•  í´ë¼ì´ì–¸íŠ¸ ID: "))
        move_client_to_completed(client_id)
        print("í´ë¼ì´ì–¸íŠ¸ ì‘ì—… ì™„ë£Œ ì²˜ë¦¬ ì™„ë£Œ")

    def view_client_status_prompt(self):
        view_clients()
        client_id = int(input("ìƒíƒœ ì¡°íšŒí•  í´ë¼ì´ì–¸íŠ¸ ID: "))
        status = view_client_status(client_id)
        if status:
            print(f"\ní´ë¼ì´ì–¸íŠ¸ ID: {status['client_id']}")
            print(f"ì´ë¦„: {status['client_name']}")
            print(f"êµ¬ì¶•ëœ ë°±ë§í¬ ìˆ˜: {status['built_count']}")
            print(f"ë‚¨ì€ ë°±ë§í¬ ìˆ˜: {status['remaining_count']}")
            print(f"ë‚¨ì€ ê¸°ê°„: {status['remaining_days']} ì¼")
        else:
            print("í•´ë‹¹ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def pause_resume_client_prompt(self):
        view_clients()
        client_id = int(input("ì¼ì‹œ ì •ì§€/ì¬ê°œí•  í´ë¼ì´ì–¸íŠ¸ ID: "))
        action = input("ì¼ì‹œì •ì§€(pause) / ì¬ê°œ(resume): ").strip().lower()
        if action == "pause":
            pause_client(client_id)
            print(f"{client_id} í´ë¼ì´ì–¸íŠ¸ ì¼ì‹œì •ì§€ ì™„ë£Œ")
        elif action == "resume":
            resume_client(client_id)
            print(f"{client_id} í´ë¼ì´ì–¸íŠ¸ ì¬ê°œ ì™„ë£Œ")
        else:
            print("ì˜ëª»ëœ ëª…ë ¹ì…ë‹ˆë‹¤.")

    def view_client_keywords_prompt(self):
        """íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ì˜ í‚¤ì›Œë“œë¥¼ í™•ì¸í•˜ëŠ” ê°„ë‹¨í•œ ë©”ë‰´"""
        view_clients()
        cid = input_with_validation(
            "í‚¤ì›Œë“œë¥¼ ì¡°íšŒí•  í´ë¼ì´ì–¸íŠ¸ ID: ", lambda x: x.isdigit()
        )
        cid = int(cid)
        keywords = get_client_keywords(cid)
        if keywords:
            print(f"í´ë¼ì´ì–¸íŠ¸ {cid}ì˜ í‚¤ì›Œë“œ ëª©ë¡:")
            for kw in keywords:
                print(" -", kw)
        else:
            print("ë“±ë¡ëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    def crawl_pbn_content_prompt(self):
        """PBN ì½˜í…ì¸  í¬ë¡¤ë§ ì‹¤í–‰"""
        print("ğŸ•·ï¸ PBN ì½˜í…ì¸  í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("âš ï¸ ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if confirm != "y":
            print("í¬ë¡¤ë§ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return

        try:
            # ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì„¤ì •
            max_workers = input("ë™ì‹œ í¬ë¡¤ë§ ì‚¬ì´íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 3): ").strip()
            max_workers = int(max_workers) if max_workers.isdigit() else 3

            # í¬ë¡¤ë§ ì‹¤í–‰
            results = self.pbn_crawler.crawl_all_pbn_sites(max_workers=max_workers)

            print("\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"ğŸ“Š ì²˜ë¦¬ëœ ì‚¬ì´íŠ¸: {results['total_sites']}ê°œ")
            print(f"âœ… ì„±ê³µí•œ ì‚¬ì´íŠ¸: {results['successful_sites']}ê°œ")
            print(f"ğŸ“„ ì´ ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸: {results['total_posts']:,}ê°œ")
            print(f"ğŸ’¾ ì €ì¥ëœ í¬ìŠ¤íŠ¸: {results['saved_posts']:,}ê°œ")

        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def view_pbn_database_stats_prompt(self):
        """PBN ì½˜í…ì¸  ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
        try:
            stats = self.pbn_crawler.get_database_stats()

            print("\nğŸ“Š PBN ì½˜í…ì¸  ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
            print("=" * 50)
            print(f"ğŸ“„ ì´ í¬ìŠ¤íŠ¸ ìˆ˜: {stats['total_posts']:,}ê°œ")
            print(f"ğŸŒ ì´ ì‚¬ì´íŠ¸ ìˆ˜: {stats['total_sites']}ê°œ")

            if stats["site_stats"]:
                print(f"\nğŸ“‹ ì‚¬ì´íŠ¸ë³„ í¬ìŠ¤íŠ¸ ìˆ˜ (ìƒìœ„ 10ê°œ):")
                for site_url, post_count in stats["site_stats"][:10]:
                    print(f"   â€¢ {site_url}: {post_count:,}ê°œ")

            if stats["recent_crawls"]:
                print(f"\nğŸ•°ï¸ ìµœê·¼ í¬ë¡¤ë§ ë¡œê·¸:")
                for site_url, total, success, status, created_at in stats[
                    "recent_crawls"
                ]:
                    print(
                        f"   â€¢ {site_url}: {success}/{total} ({status}) - {created_at}"
                    )

        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def test_similar_posts_prompt(self):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ í¬ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        try:
            # í‚¤ì›Œë“œ ì…ë ¥
            keywords_input = input(
                "ê²€ìƒ‰í•  í‚¤ì›Œë“œë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„): "
            ).strip()
            if not keywords_input:
                print("í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            keywords = [kw.strip() for kw in keywords_input.split(",")]

            # ê²€ìƒ‰ ì˜µì…˜
            limit_input = input("ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10): ").strip()
            limit = int(limit_input) if limit_input.isdigit() else 10

            similarity_input = input(
                "ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (0.0-1.0, ê¸°ë³¸ê°’: 0.3): "
            ).strip()
            min_similarity = float(similarity_input) if similarity_input else 0.3

            print(f"\nğŸ” '{', '.join(keywords)}' í‚¤ì›Œë“œë¡œ ìœ ì‚¬í•œ í¬ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘...")

            # AI ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ì‚¬ ì‹œë„
            if (
                hasattr(self, "similarity_system")
                and self.similarity_system is not None
                and self.similarity_system.faiss_index is not None
                and self.similarity_system.similarity_model is not None
            ):
                print("   ğŸ§  AI ê¸°ë°˜ FAISS ì‹œìŠ¤í…œ ì‚¬ìš© ì¤‘...")

                # ë””ë²„ê¹…: similarity_system ë‚´ë¶€ ìƒíƒœ í™•ì¸
                print(
                    f"   ğŸ” ë””ë²„ê¹… - faiss_index: {self.similarity_system.faiss_index is not None}"
                )
                print(
                    f"   ğŸ” ë””ë²„ê¹… - similarity_model: {self.similarity_system.similarity_model is not None}"
                )
                print(
                    f"   ğŸ” ë””ë²„ê¹… - post_metadata: {len(self.similarity_system.post_metadata) if self.similarity_system.post_metadata else 0}ê°œ"
                )

                # ê²€ìƒ‰ ì‹¤í–‰ (AI ê¸°ë°˜ FAISS ì‹œìŠ¤í…œ ì‚¬ìš©)
                similar_posts = self.similarity_system.find_similar_posts_fast(
                    keywords,
                    limit=limit,
                    min_similarity=min_similarity,
                    random_selection=True,
                )
            else:
                print("   âš ï¸ AI ìœ ì‚¬ë„ ì‹œìŠ¤í…œì´ ì—†ì–´ì„œ ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                print("   ğŸ”„ AI ì‹œìŠ¤í…œ ê°•ì œ ì¬ì´ˆê¸°í™” ì‹œë„ ì¤‘...")
                try:
                    print("   ğŸ¤– ImprovedSimilaritySystem ê°•ì œ ì´ˆê¸°í™” ì¤‘...")
                    self.similarity_system = ImprovedSimilaritySystem()
                    print("   âœ… AI ìœ ì‚¬ë„ ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™” ì™„ë£Œ")

                    # ì¬ì´ˆê¸°í™” í›„ ìƒíƒœ í™•ì¸
                    print(
                        f"   ğŸ” ì¬ì´ˆê¸°í™” í™•ì¸ - faiss_index: {self.similarity_system.faiss_index is not None}"
                    )
                    print(
                        f"   ğŸ” ì¬ì´ˆê¸°í™” í™•ì¸ - similarity_model: {self.similarity_system.similarity_model is not None}"
                    )
                    print(
                        f"   ğŸ” ì¬ì´ˆê¸°í™” í™•ì¸ - post_metadata: {len(self.similarity_system.post_metadata) if self.similarity_system.post_metadata else 0}ê°œ"
                    )

                    similar_posts = self.similarity_system.find_similar_posts_fast(
                        keywords,
                        limit=limit,
                        min_similarity=min_similarity,
                        random_selection=True,
                    )
                except Exception as e:
                    print(f"   âŒ AI ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    print("   ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
                    import traceback

                    traceback.print_exc()
                    print("   ğŸ”„ ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    # ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ ì‚¬ìš©
                    similar_posts = self.pbn_crawler.find_similar_posts(
                        keywords, limit=limit, min_similarity=min_similarity
                    )

            if similar_posts:
                print(f"\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ({len(similar_posts)}ê°œ):")
                print("=" * 80)

                for i, post in enumerate(similar_posts, 1):
                    similarity = post.get("similarity_score", 0)
                    print(f"{i}. ğŸ“„ {post['title']}")
                    print(f"   ğŸ”— {post['url']}")
                    print(f"   ğŸ“Š ìœ ì‚¬ë„: {similarity:.3f}")
                    print(f"   ğŸŒ ì‚¬ì´íŠ¸: {post['site_url']}")
                    print(f"   ğŸ“ ë‹¨ì–´ ìˆ˜: {post.get('word_count', 0)}")
                    print("-" * 80)
            else:
                print("âŒ ìœ ì‚¬í•œ í¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   ğŸ’¡ íŒ: ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•˜ê±°ë‚˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def single_test_prompt(self):
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‚¬ì´íŠ¸+í‚¤ì›Œë“œ ì§€ì •)"""
        print("\nğŸ§ª ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("=" * 50)

        try:
            # 1. í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ URL ì…ë ¥
            client_site_url = input("í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ URL ì…ë ¥: ").strip()
            if not client_site_url:
                print("âŒ ì‚¬ì´íŠ¸ URLì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            # URL í˜•ì‹ ê²€ì¦
            if not client_site_url.startswith(("http://", "https://")):
                client_site_url = "https://" + client_site_url

            # 2. í‚¤ì›Œë“œ ì…ë ¥
            keyword = input("í…ŒìŠ¤íŠ¸í•  í‚¤ì›Œë“œ ì…ë ¥: ").strip()
            if not keyword:
                print("âŒ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            # 3. PBN ì‚¬ì´íŠ¸ ì„ íƒ
            print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ PBN ì‚¬ì´íŠ¸ ëª©ë¡:")
            pbn_sites = get_all_pbn_sites()
            if not pbn_sites:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ PBN ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ì•± íŒ¨ìŠ¤ì›Œë“œê°€ ìˆëŠ” ì‚¬ì´íŠ¸ë§Œ í•„í„°ë§
            valid_pbn_sites = [site for site in pbn_sites if site[4]]
            if not valid_pbn_sites:
                print("âŒ ì•± íŒ¨ìŠ¤ì›Œë“œê°€ ì„¤ì •ëœ PBN ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            print("ì‚¬ìš© ê°€ëŠ¥í•œ PBN ì‚¬ì´íŠ¸:")
            for i, site in enumerate(valid_pbn_sites, 1):
                site_id, site_url, site_user, _, _ = site
                print(f"  {i}. {site_url} (ì‚¬ìš©ì: {site_user})")

            # PBN ì‚¬ì´íŠ¸ ì„ íƒ
            while True:
                try:
                    choice = input(
                        f"PBN ì‚¬ì´íŠ¸ ì„ íƒ (1-{len(valid_pbn_sites)}): "
                    ).strip()
                    if not choice.isdigit():
                        print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        continue
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(valid_pbn_sites):
                        selected_pbn_site = valid_pbn_sites[choice_idx]
                        break
                    else:
                        print(
                            f"âŒ 1ë¶€í„° {len(valid_pbn_sites)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                        )
                except KeyboardInterrupt:
                    print("\nâŒ í…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return

            # 4. í…ŒìŠ¤íŠ¸ìš© í´ë¼ì´ì–¸íŠ¸ íŠœí”Œ ìƒì„±
            test_client_tuple = (
                999,  # ì„ì‹œ í´ë¼ì´ì–¸íŠ¸ ID
                "í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸",  # í´ë¼ì´ì–¸íŠ¸ ì´ë¦„
                client_site_url,  # í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸ URL
                None,  # total_backlinks (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                None,  # remaining_days (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                None,  # built_count (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                None,  # status (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                None,  # daily_min (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                None,  # daily_max (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            )

            print(f"\nğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            print(f"   ğŸ“ í‚¤ì›Œë“œ: {keyword}")
            print(f"   ğŸŒ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸: {client_site_url}")
            print(f"   ğŸ”— PBN ì‚¬ì´íŠ¸: {selected_pbn_site[1]}")
            print("=" * 50)

            # 5. PBN ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            pbn_site_dict = {
                "site_id": selected_pbn_site[0],
                "site_url": selected_pbn_site[1],
                "username": selected_pbn_site[2],
                "password": selected_pbn_site[3],
                "app_password": selected_pbn_site[4],
            }

            # 6. ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            success = asyncio.run(
                self.process_client(
                    test_client_tuple, [selected_pbn_site], test_keyword=keyword
                )
            )

            # 6. ê²°ê³¼ ì¶œë ¥
            print("\n" + "=" * 50)
            if success:
                print("ğŸ‰ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                print(f"âœ… í‚¤ì›Œë“œ '{keyword}'ì— ëŒ€í•œ í¬ìŠ¤íŒ…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"ğŸ”— PBN ì‚¬ì´íŠ¸: {selected_pbn_site[1]}")
                print(f"ğŸŒ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´íŠ¸: {client_site_url}")
            else:
                print("âŒ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                print("   ğŸ’¡ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ PBN ì‚¬ì´íŠ¸ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            print("=" * 50)

        except KeyboardInterrupt:
            print("\nâŒ í…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback

            traceback.print_exc()

    def main(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        while True:
            self.display_menu()
            choice = input("ì‘ì—… ì„ íƒ(q ì¢…ë£Œ): ").lower()

            if choice == "1":
                asyncio.run(self.run_automated_campaign())
            elif choice == "2":
                self.add_pbn_site_prompt()
            elif choice == "3":
                view_pbn_sites()
            elif choice == "4":
                self.delete_pbn_site_prompt()
            elif choice == "5":
                self.add_client_prompt()
            elif choice == "6":
                view_clients()
            elif choice == "7":
                self.update_client_prompt()
            elif choice == "8":
                self.extend_or_reduce_days_prompt()
            elif choice == "9":
                self.complete_client_prompt()
            elif choice == "10":
                view_completed_clients()
            elif choice == "11":
                show_all_tables()
            elif choice == "12":
                self.view_client_status_prompt()
            elif choice == "13":
                self.pause_resume_client_prompt()
            elif choice == "14":
                pause_all_clients()
                print("ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì¼ì‹œì •ì§€ ì™„ë£Œ")
            elif choice == "15":
                resume_all_clients()
                print("ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì¬ê°œ ì™„ë£Œ")
            elif choice == "16":
                output_file = input("ì—‘ì…€ íŒŒì¼ëª…(ê¸°ë³¸: backlink_report.xlsx): ").strip()
                if not output_file:
                    output_file = "backlink_report.xlsx"
                save_all_backlinks_to_excel(output_file)
            elif choice == "17":
                self.view_client_keywords_prompt()
            elif choice == "18":
                remove_duplicate_clients()
            elif choice == "19":
                self.load_active_clients_and_log()
            elif choice == "20":
                posts = fetch_all_posts()
                if posts:
                    print("\nğŸ“‹ í¬ìŠ¤íŠ¸ ê¸°ë¡:")
                    for post in posts[:10]:  # ìµœê·¼ 10ê°œë§Œ í‘œì‹œ
                        print(
                            f"ID: {post[0]}, í´ë¼ì´ì–¸íŠ¸: {post[2]}, í‚¤ì›Œë“œ: {post[4]}"
                        )
                    if len(posts) > 10:
                        print(f"... ì´ {len(posts)}ê°œì˜ í¬ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                else:
                    print("í¬ìŠ¤íŠ¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            elif choice == "21":
                self.crawl_pbn_content_prompt()
            elif choice == "22":
                self.view_pbn_database_stats_prompt()
            elif choice == "23":
                self.test_similar_posts_prompt()
            elif choice == "24":
                self.single_test_prompt()
            elif choice == "q":
                print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                sys.exit(0)
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ê³ ë„í™”ëœ PBN ë°±ë§í¬ ìë™í™” ì‹œìŠ¤í…œ v2.0")
    print("=" * 60)

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = EnhancedPBNSystem()

    # ë©”ì¸ ë©”ë‰´ ì‹¤í–‰
    system.main()


if __name__ == "__main__":
    main()
